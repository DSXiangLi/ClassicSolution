{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "282d374f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import time \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from gensim.models.phrases import Phrases\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from src.train_utils import set_seed, ModelSave, get_torch_device, EarlyStop, TrainParams\n",
    "from src.evaluation import classification_inference\n",
    "from src.metric import  multi_cls_metrics,multi_cls_log\n",
    "from src.dataset.tokenizer import GensimTokenizer\n",
    "\n",
    "from iflytek_app.dataset import MixDataset\n",
    "from iflytek_app.models import Textcnn\n",
    "from iflytek_app.process import train_process, test_process, result_process, kfold_inference\n",
    "\n",
    "device = get_torch_device()\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb170d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                id           l1           l2          len\n",
      "count  4199.000000  4199.000000  4199.000000  4199.000000\n",
      "mean   2099.000000     8.969278    37.087878    46.057156\n",
      "std    1212.291219     4.576621    79.204914    79.332999\n",
      "min       0.000000     2.000000     1.000000     4.000000\n",
      "25%    1049.500000     5.000000     6.000000    15.000000\n",
      "50%    2099.000000     8.000000    12.000000    22.000000\n",
      "75%    3148.500000    12.000000    26.000000    36.000000\n",
      "max    4198.000000    32.000000   946.000000   961.000000\n",
      "{'14784131 14858934 14784131 14845064': 0, '14852788 14717848 15639958 15632020': 1, '14844856 14724258 14925237 14854807': 2, '14925756 15639967 14853254 14728639': 3, '14844593 14924945': 4, '15709098 14716590 14924703 14779559': 5, '14726332 14728344 14854542 14844591': 6, '14858934 15636660 15704193 14849963': 7, '15710359 14847407 14845602 14859696': 8, '14794687 14782344': 9, '15630486 15702410 14718849 15709093': 10, '15632285 15706536 14721977 14925219': 11, '14782903 15634620 15638402 15706300': 12, '14844093 15705739 14854331 15699885': 13, '14856354 14844592': 14, '14847385 14844587 14848641 14847398': 15, '14783134 15697333 14854817 14925479': 16, '14924216 14781104 14717848 14791612': 17, '14786237 15697082 14722731 14924977': 18}\n"
     ]
    }
   ],
   "source": [
    "phraser= Phrases.load('./checkpoint/phrase_tokenizer')\n",
    "c2v = GensimTokenizer( Word2Vec.load('./checkpoint/char_min1_win5_sg_d100'))\n",
    "w2v = GensimTokenizer(Word2Vec.load('./checkpoint/phrase_min1_win5_sg_d100'), phraser)\n",
    "w2v.init_vocab()\n",
    "c2v.init_vocab()\n",
    "\n",
    "df, label2idx = train_process()\n",
    "test = test_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb09021",
   "metadata": {},
   "source": [
    "1. Random Delete\n",
    "2. Random Insert\n",
    "3. Random Swap\n",
    "4. Synonym Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b8f32b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocess.augment import *\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5cccb350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4199.000000</td>\n",
       "      <td>4199.000000</td>\n",
       "      <td>4199.000000</td>\n",
       "      <td>4199.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2099.000000</td>\n",
       "      <td>8.969278</td>\n",
       "      <td>37.087878</td>\n",
       "      <td>46.057156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1212.291219</td>\n",
       "      <td>4.576621</td>\n",
       "      <td>79.204914</td>\n",
       "      <td>79.332999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1049.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2099.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3148.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4198.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>946.000000</td>\n",
       "      <td>961.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id           l1           l2          len\n",
       "count  4199.000000  4199.000000  4199.000000  4199.000000\n",
       "mean   2099.000000     8.969278    37.087878    46.057156\n",
       "std    1212.291219     4.576621    79.204914    79.332999\n",
       "min       0.000000     2.000000     1.000000     4.000000\n",
       "25%    1049.500000     5.000000     6.000000    15.000000\n",
       "50%    2099.000000     8.000000    12.000000    22.000000\n",
       "75%    3148.500000    12.000000    26.000000    36.000000\n",
       "max    4198.000000    32.000000   946.000000   961.000000"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93ea39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_samples = [] \n",
    "\n",
    "rand_del = WordDelete(w2v, max_sample=1, filters=())\n",
    "rand_synon= W2vSynonymous(w2v, max_sample=1, filters=())\n",
    "rand_swap = WordSwap(w2v, max_sample=1, filters=())\n",
    "\n",
    "\n",
    "for index, row in enumerate(df.iterrows()):\n",
    "    text = row[1]['description']\n",
    "    name = row[1]['name']\n",
    "    label = row[1]['label']\n",
    "    for aug_text in rand_del.augment(text):\n",
    "        aug_samples.append((index, name, aug_text.split(' '), label, 'word_random_delete'))\n",
    "    for aug_text in rand_swap.augment(text):\n",
    "        aug_samples.append((index, name, aug_text.split(' '), label, 'word_random_swap'))\n",
    "    for aug_text in rand_synon.augment(text):\n",
    "        aug_samples.append((index, name, aug_text.split(' '), label, 'word_random_synonymous'))\n",
    "        \n",
    "        \n",
    "# rand_del = WordDelete(c2v, filters=())\n",
    "# rand_synon= W2vSynonymous(c2v, filters=())\n",
    "# rand_swap = WordSwap(c2v, filters=())\n",
    "\n",
    "# for index, row in enumerate(df.iterrows()):\n",
    "#     text = row[1]['description']\n",
    "#     name = row[1]['name']\n",
    "#     label = row[1]['label']\n",
    "#     for aug_text in rand_del.augment(text):\n",
    "#         aug_samples.append((index, name, aug_text.split(' '), label, 'char_random_delete'))\n",
    "#     for aug_text in rand_swap.augment(text):\n",
    "#         aug_samples.append((index, name, aug_text.split(' '), label, 'char_random_swap'))\n",
    "#     for aug_text in rand_synon.augment(text):\n",
    "#         aug_samples.append((index, name, aug_text.split(' '), label, 'char_random_synonymous'))\n",
    "        \n",
    "df_aug = pd.DataFrame(aug_samples, columns= ['index', 'name','description','label','augment'])    \n",
    "df_aug['description'] = df_aug['description'].map(lambda x: list(itertools.chain(*[i.split('_') for i in x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf2a6993",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_steps = 10\n",
    "save_steps = 20\n",
    "tp = TrainParams(\n",
    "    epoch_size=30,\n",
    "    lr=1e-3,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    max_seq_len=1000,\n",
    "    batch_size=32,\n",
    "    aug_batch_size=8,\n",
    "    dropout_rate=0.5,\n",
    "    label_size = len(label2idx),\n",
    "    vocab_size = w2v.vocab_size,\n",
    "    embedding_dim = w2v.embedding_size + c2v.embedding_size,\n",
    "    embedding1=c2v.embedding, \n",
    "    embedding2 =w2v.embedding,\n",
    "    num_train_steps=int(df.shape[0]/5 *4), \n",
    "    filter_size=70,\n",
    "    kernel_size_list = [2,3,4,5],\n",
    "    hidden_size = 100,\n",
    "    early_stop_params = {\n",
    "        'monitor':'f1_micro',\n",
    "        'mode':'max',\n",
    "        'min_delta': 0,\n",
    "        'patience':5,\n",
    "        'verbose':False\n",
    "    },\n",
    "    scheduler_params={'mode': 'max',\n",
    "                     'factor': 0.5,\n",
    "                     'patience': 2,\n",
    "                     'verbose': True,\n",
    "                     'threshold':0.0001,\n",
    "                     'threshold_mode':'rel',\n",
    "                     'cooldown':0,\n",
    "                     'min_lr':1e-6}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3df6993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoint/textcnn_aug/k0 model cleaned\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   10    |   5.074656   |     -     |   1.88   \n",
      "   1    |   20    |   3.778959   |     -     |   1.52   \n",
      "   1    |   30    |   2.685808   |     -     |   6.13   \n",
      "   1    |   40    |   2.526789   |     -     |   1.52   \n",
      "   1    |   50    |   2.390051   |     -     |   5.80   \n",
      "   1    |   60    |   2.401289   |     -     |   1.65   \n",
      "   1    |   70    |   2.231517   |     -     |   6.01   \n",
      "   1    |   80    |   2.136148   |     -     |   1.52   \n",
      "   1    |   90    |   2.196325   |     -     |   5.59   \n",
      "   1    |   100   |   2.053561   |     -     |   1.48   \n",
      "   1    |   104   |   1.974780   |     -     |   4.72   \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   2.766585   |  1.977645  |   42.25  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   1    |  13.455%  |  73.853%  |  27.303%  |     9.748%      |   13.455%    |  37.381%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   1    |  37.381%  |     -     |     -     |     37.381%     |   37.381%    |  37.381%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   2    |   10    |   5.745100   |     -     |   1.68   \n",
      "   2    |   20    |   2.644071   |     -     |   1.54   \n",
      "   2    |   30    |   1.940205   |     -     |   5.68   \n",
      "   2    |   40    |   1.921588   |     -     |   1.49   \n",
      "   2    |   50    |   1.678318   |     -     |   5.68   \n",
      "   2    |   60    |   1.673087   |     -     |   1.50   \n",
      "   2    |   70    |   1.762720   |     -     |   5.79   \n",
      "   2    |   80    |   1.561139   |     -     |   1.59   \n",
      "   2    |   90    |   1.689801   |     -     |   5.68   \n",
      "   2    |   100   |   1.619602   |     -     |   1.54   \n",
      "   2    |   104   |   1.602160   |     -     |   4.96   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   2.254904   |  1.649378  |   41.41  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   2    |  34.012%  |  78.298%  |  37.914%  |     29.660%     |   34.012%    |  52.500%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   2    |  52.500%  |     -     |     -     |     52.500%     |   52.500%    |  52.500%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   3    |   10    |   1.915697   |     -     |   1.76   \n",
      "   3    |   20    |   1.705831   |     -     |   1.52   \n",
      "   3    |   30    |   1.411283   |     -     |   5.76   \n",
      "   3    |   40    |   1.453711   |     -     |   1.53   \n",
      "   3    |   50    |   1.481652   |     -     |   5.72   \n",
      "   3    |   60    |   1.521116   |     -     |   1.50   \n",
      "   3    |   70    |   1.641227   |     -     |   6.05   \n",
      "   3    |   80    |   1.255122   |     -     |   1.51   \n",
      "   3    |   90    |   1.484928   |     -     |   5.66   \n",
      "   3    |   100   |   1.481656   |     -     |   1.52   \n",
      "   3    |   104   |   1.395234   |     -     |   5.24   \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   1.548258   |  1.444816  |   42.05  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   3    |  35.729%  |  82.052%  |  44.712%  |     46.518%     |   35.729%    |  56.071%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   3    |  56.071%  |     -     |     -     |     56.071%     |   56.071%    |  56.071%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   4    |   10    |   1.428500   |     -     |   1.77   \n",
      "   4    |   20    |   1.588959   |     -     |   1.66   \n",
      "   4    |   30    |   1.347668   |     -     |   5.84   \n",
      "   4    |   40    |   1.358947   |     -     |   1.48   \n",
      "   4    |   50    |   1.067085   |     -     |   5.64   \n",
      "   4    |   60    |   1.272016   |     -     |   1.50   \n",
      "   4    |   70    |   1.559301   |     -     |   5.63   \n",
      "   4    |   80    |   1.099063   |     -     |   1.58   \n",
      "   4    |   90    |   1.416616   |     -     |   6.18   \n",
      "   4    |   100   |   1.496532   |     -     |   1.57   \n",
      "   4    |   104   |   0.855444   |     -     |   5.34   \n",
      "----------------------------------------------------------------------\n",
      "   4    |    -    |   1.357665   |  1.359127  |   42.41  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   4    |  40.741%  |  83.144%  |  49.604%  |     45.936%     |   40.741%    |  61.429%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   4    |  61.429%  |     -     |     -     |     61.429%     |   61.429%    |  61.429%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   5    |   10    |   1.252033   |     -     |   1.80   \n",
      "   5    |   20    |   1.339121   |     -     |   1.53   \n",
      "   5    |   30    |   1.381889   |     -     |   5.71   \n",
      "   5    |   40    |   1.080723   |     -     |   1.49   \n",
      "   5    |   50    |   1.125628   |     -     |   5.73   \n",
      "   5    |   60    |   0.981703   |     -     |   1.51   \n",
      "   5    |   70    |   1.123748   |     -     |   5.82   \n",
      "   5    |   80    |   1.174108   |     -     |   1.53   \n",
      "   5    |   90    |   1.112246   |     -     |   5.74   \n",
      "   5    |   100   |   1.310033   |     -     |   1.52   \n",
      "   5    |   104   |   1.066881   |     -     |   4.79   \n",
      "----------------------------------------------------------------------\n",
      "   5    |    -    |   1.195499   |  1.219723  |   41.40  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   5    |  46.685%  |  85.010%  |  52.594%  |     48.368%     |   46.685%    |  64.762%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   5    |  64.762%  |     -     |     -     |     64.762%     |   64.762%    |  64.762%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   6    |   10    |   1.114518   |     -     |   1.78   \n",
      "   6    |   20    |   1.135100   |     -     |   1.56   \n",
      "   6    |   30    |   1.034290   |     -     |   5.78   \n",
      "   6    |   40    |   0.949090   |     -     |   1.52   \n",
      "   6    |   50    |   0.949401   |     -     |   5.89   \n",
      "   6    |   60    |   1.396009   |     -     |   1.52   \n",
      "   6    |   70    |   1.036188   |     -     |   5.70   \n",
      "   6    |   80    |   1.019978   |     -     |   1.50   \n",
      "   6    |   90    |   1.349590   |     -     |   5.77   \n",
      "   6    |   100   |   0.875014   |     -     |   1.53   \n",
      "   6    |   104   |   0.924416   |     -     |   5.08   \n",
      "----------------------------------------------------------------------\n",
      "   6    |    -    |   1.090423   |  1.292472  |   42.03  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   6    |  45.984%  |  84.690%  |  53.477%  |     56.111%     |   45.984%    |  63.929%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   6    |  63.929%  |     -     |     -     |     63.929%     |   63.929%    |  63.929%  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   7    |   10    |   1.311979   |     -     |   1.94   \n",
      "   7    |   20    |   1.048122   |     -     |   1.51   \n",
      "   7    |   30    |   0.764053   |     -     |   6.04   \n",
      "   7    |   40    |   1.284393   |     -     |   1.52   \n",
      "   7    |   50    |   0.944036   |     -     |   5.79   \n",
      "   7    |   60    |   0.938564   |     -     |   1.52   \n",
      "   7    |   70    |   1.238071   |     -     |   5.90   \n",
      "   7    |   80    |   0.904513   |     -     |   1.56   \n",
      "   7    |   90    |   1.246240   |     -     |   5.86   \n",
      "   7    |   100   |   1.144437   |     -     |   1.56   \n",
      "   7    |   104   |   0.921485   |     -     |   4.97   \n",
      "----------------------------------------------------------------------\n",
      "   7    |    -    |   1.088866   |  1.378038  |   42.60  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   7    |  45.685%  |  83.852%  |  53.213%  |     50.566%     |   45.685%    |  63.571%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   7    |  63.571%  |     -     |     -     |     63.571%     |   63.571%    |  63.571%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   8    |   10    |   1.192634   |     -     |   1.72   \n",
      "   8    |   20    |   1.463281   |     -     |   1.56   \n",
      "   8    |   30    |   1.013976   |     -     |   5.87   \n",
      "   8    |   40    |   0.956168   |     -     |   1.51   \n",
      "   8    |   50    |   0.777268   |     -     |   5.75   \n",
      "   8    |   60    |   0.885909   |     -     |   1.51   \n",
      "   8    |   70    |   0.876279   |     -     |   5.74   \n",
      "   8    |   80    |   1.009692   |     -     |   1.51   \n",
      "   8    |   90    |   0.590843   |     -     |   5.67   \n",
      "   8    |   100   |   0.958462   |     -     |   1.53   \n",
      "   8    |   104   |   0.671568   |     -     |   4.84   \n",
      "----------------------------------------------------------------------\n",
      "   8    |    -    |   0.972346   |  1.254567  |   41.50  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   8    |  49.998%  |  85.781%  |  56.735%  |     53.311%     |   49.998%    |  66.429%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   8    |  66.429%  |     -     |     -     |     66.429%     |   66.429%    |  66.429%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   9    |   10    |   0.848788   |     -     |   1.75   \n",
      "   9    |   20    |   1.228956   |     -     |   1.51   \n",
      "   9    |   30    |   1.109727   |     -     |   5.63   \n",
      "   9    |   40    |   0.654351   |     -     |   1.52   \n",
      "   9    |   50    |   0.994536   |     -     |   5.94   \n",
      "   9    |   60    |   0.960221   |     -     |   1.51   \n",
      "   9    |   70    |   0.687116   |     -     |   5.76   \n",
      "   9    |   80    |   0.658572   |     -     |   1.51   \n",
      "   9    |   90    |   1.202060   |     -     |   5.79   \n",
      "   9    |   100   |   0.892791   |     -     |   1.52   \n",
      "   9    |   104   |   0.939945   |     -     |   4.89   \n",
      "----------------------------------------------------------------------\n",
      "   9    |    -    |   0.932498   |  1.167062  |   41.63  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   9    |  50.358%  |  84.292%  |  56.649%  |     55.782%     |   50.358%    |  68.810%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   9    |  68.810%  |     -     |     -     |     68.810%     |   68.810%    |  68.810%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  10    |   10    |   1.016402   |     -     |   1.71   \n",
      "  10    |   20    |   1.196704   |     -     |   1.50   \n",
      "  10    |   30    |   0.519880   |     -     |   5.67   \n",
      "  10    |   40    |   1.227323   |     -     |   1.50   \n",
      "  10    |   50    |   0.865380   |     -     |   5.71   \n",
      "  10    |   60    |   0.621670   |     -     |   1.50   \n",
      "  10    |   70    |   0.884601   |     -     |   5.63   \n",
      "  10    |   80    |   0.701234   |     -     |   1.49   \n",
      "  10    |   90    |   0.738317   |     -     |   5.69   \n",
      "  10    |   100   |   1.297398   |     -     |   1.48   \n",
      "  10    |   104   |   0.799468   |     -     |   4.75   \n",
      "----------------------------------------------------------------------\n",
      "  10    |    -    |   0.912532   |  1.125223  |   40.78  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  10    |  53.013%  |  87.456%  |  59.328%  |     60.796%     |   53.013%    |  69.286%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  10    |  69.286%  |     -     |     -     |     69.286%     |   69.286%    |  69.286%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  11    |   10    |   0.815635   |     -     |   1.78   \n",
      "  11    |   20    |   1.037211   |     -     |   1.51   \n",
      "  11    |   30    |   0.935848   |     -     |   5.70   \n",
      "  11    |   40    |   1.051876   |     -     |   1.49   \n",
      "  11    |   50    |   0.740528   |     -     |   5.66   \n",
      "  11    |   60    |   0.641827   |     -     |   1.52   \n",
      "  11    |   70    |   0.791795   |     -     |   5.64   \n",
      "  11    |   80    |   0.542799   |     -     |   1.50   \n",
      "  11    |   90    |   0.528133   |     -     |   5.66   \n",
      "  11    |   100   |   0.817508   |     -     |   1.49   \n",
      "  11    |   104   |   1.026365   |     -     |   4.76   \n",
      "----------------------------------------------------------------------\n",
      "  11    |    -    |   0.807237   |  1.290338  |   40.87  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  11    |  50.900%  |  85.763%  |  56.695%  |     57.930%     |   50.900%    |  67.262%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  11    |  67.262%  |     -     |     -     |     67.262%     |   67.262%    |  67.262%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  12    |   10    |   0.760112   |     -     |   1.74   \n",
      "  12    |   20    |   1.163180   |     -     |   1.52   \n",
      "  12    |   30    |   0.631856   |     -     |   5.70   \n",
      "  12    |   40    |   0.959855   |     -     |   1.50   \n",
      "  12    |   50    |   0.761113   |     -     |   5.65   \n",
      "  12    |   60    |   0.643782   |     -     |   1.49   \n",
      "  12    |   70    |   0.716070   |     -     |   5.68   \n",
      "  12    |   80    |   0.845171   |     -     |   1.46   \n",
      "  12    |   90    |   0.764652   |     -     |   5.65   \n",
      "  12    |   100   |   0.690680   |     -     |   1.51   \n",
      "  12    |   104   |   0.621097   |     -     |   4.78   \n",
      "----------------------------------------------------------------------\n",
      "  12    |    -    |   0.794319   |  1.264700  |   40.83  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  12    |  47.973%  |  85.465%  |  56.253%  |     57.311%     |   47.973%    |  67.262%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  12    |  67.262%  |     -     |     -     |     67.262%     |   67.262%    |  67.262%  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  13    |   10    |   0.731968   |     -     |   1.75   \n",
      "  13    |   20    |   0.980180   |     -     |   1.61   \n",
      "  13    |   30    |   0.793977   |     -     |   5.97   \n",
      "  13    |   40    |   0.586515   |     -     |   1.58   \n",
      "  13    |   50    |   0.742843   |     -     |   5.81   \n",
      "  13    |   60    |   0.519622   |     -     |   1.52   \n",
      "  13    |   70    |   0.493908   |     -     |   5.78   \n",
      "  13    |   80    |   0.763564   |     -     |   1.53   \n",
      "  13    |   90    |   0.806786   |     -     |   5.92   \n",
      "  13    |   100   |   0.908289   |     -     |   1.61   \n",
      "  13    |   104   |   1.448251   |     -     |   4.94   \n",
      "----------------------------------------------------------------------\n",
      "  13    |    -    |   0.767322   |  1.179225  |   42.31  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  13    |  54.148%  |  86.992%  |  58.561%  |     60.424%     |   54.148%    |  69.881%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  13    |  69.881%  |     -     |     -     |     69.881%     |   69.881%    |  69.881%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  14    |   10    |   1.074217   |     -     |   1.74   \n",
      "  14    |   20    |   0.893173   |     -     |   1.49   \n",
      "  14    |   30    |   0.710944   |     -     |   5.61   \n",
      "  14    |   40    |   0.661480   |     -     |   1.50   \n",
      "  14    |   50    |   0.833694   |     -     |   5.63   \n",
      "  14    |   60    |   0.557694   |     -     |   1.49   \n",
      "  14    |   70    |   0.671600   |     -     |   5.62   \n",
      "  14    |   80    |   0.711972   |     -     |   1.52   \n",
      "  14    |   90    |   0.597670   |     -     |   5.58   \n",
      "  14    |   100   |   0.691972   |     -     |   1.53   \n",
      "  14    |   104   |   0.536870   |     -     |   4.74   \n",
      "----------------------------------------------------------------------\n",
      "  14    |    -    |   0.742941   |  1.182553  |   40.65  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  14    |  51.424%  |  87.226%  |  58.537%  |     56.181%     |   51.424%    |  68.333%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  14    |  68.333%  |     -     |     -     |     68.333%     |   68.333%    |  68.333%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  15    |   10    |   1.082332   |     -     |   1.81   \n",
      "  15    |   20    |   0.851511   |     -     |   1.52   \n",
      "  15    |   30    |   0.426208   |     -     |   5.71   \n",
      "  15    |   40    |   0.424351   |     -     |   1.54   \n",
      "  15    |   50    |   0.666466   |     -     |   5.74   \n",
      "  15    |   60    |   0.653661   |     -     |   1.55   \n",
      "  15    |   70    |   0.432112   |     -     |   5.75   \n",
      "  15    |   80    |   0.754128   |     -     |   1.48   \n",
      "  15    |   90    |   0.821587   |     -     |   5.76   \n",
      "  15    |   100   |   0.769749   |     -     |   1.62   \n",
      "  15    |   104   |   0.385722   |     -     |   5.09   \n",
      "----------------------------------------------------------------------\n",
      "  15    |    -    |   0.686983   |  1.152875  |   41.80  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  15    |  53.920%  |  87.107%  |  58.604%  |     61.171%     |   53.920%    |  70.476%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  15    |  70.476%  |     -     |     -     |     70.476%     |   70.476%    |  70.476%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  16    |   10    |   0.859309   |     -     |   1.68   \n",
      "  16    |   20    |   0.983113   |     -     |   1.54   \n",
      "  16    |   30    |   0.581530   |     -     |   5.75   \n",
      "  16    |   40    |   0.904606   |     -     |   1.60   \n",
      "  16    |   50    |   0.453876   |     -     |   5.98   \n",
      "  16    |   60    |   0.599892   |     -     |   1.65   \n",
      "  16    |   70    |   0.371840   |     -     |   5.98   \n",
      "  16    |   80    |   0.592572   |     -     |   1.53   \n",
      "  16    |   90    |   0.658772   |     -     |   5.76   \n",
      "  16    |   100   |   0.696560   |     -     |   1.51   \n",
      "  16    |   104   |   0.619849   |     -     |   5.03   \n",
      "----------------------------------------------------------------------\n",
      "  16    |    -    |   0.676533   |  1.174356  |   42.40  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  16    |  52.593%  |  86.502%  |  60.538%  |     60.313%     |   52.593%    |  69.286%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  16    |  69.286%  |     -     |     -     |     69.286%     |   69.286%    |  69.286%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  17    |   10    |   0.803803   |     -     |   1.79   \n",
      "  17    |   20    |   0.627847   |     -     |   1.57   \n",
      "  17    |   30    |   0.667710   |     -     |   5.92   \n",
      "  17    |   40    |   0.415582   |     -     |   1.57   \n",
      "  17    |   50    |   0.389857   |     -     |   5.87   \n",
      "  17    |   60    |   0.383637   |     -     |   1.53   \n",
      "  17    |   70    |   0.575360   |     -     |   5.80   \n",
      "  17    |   80    |   0.489445   |     -     |   1.50   \n",
      "  17    |   90    |   0.679910   |     -     |   5.73   \n",
      "  17    |   100   |   0.611537   |     -     |   1.53   \n",
      "  17    |   104   |   0.330038   |     -     |   4.81   \n",
      "----------------------------------------------------------------------\n",
      "  17    |    -    |   0.563181   |  1.239028  |   41.96  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  17    |  51.849%  |  86.275%  |  58.417%  |     61.917%     |   51.849%    |  71.071%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  17    |  71.071%  |     -     |     -     |     71.071%     |   71.071%    |  71.071%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  18    |   10    |   0.953058   |     -     |   1.71   \n",
      "  18    |   20    |   0.864596   |     -     |   1.53   \n",
      "  18    |   30    |   0.536249   |     -     |   5.86   \n",
      "  18    |   40    |   0.414776   |     -     |   1.63   \n",
      "  18    |   50    |   0.527721   |     -     |   5.86   \n",
      "  18    |   60    |   0.325066   |     -     |   1.55   \n",
      "  18    |   70    |   0.618420   |     -     |   5.91   \n",
      "  18    |   80    |   0.382708   |     -     |   1.54   \n",
      "  18    |   90    |   0.622677   |     -     |   5.89   \n",
      "  18    |   100   |   0.466980   |     -     |   1.55   \n",
      "  18    |   104   |   0.229240   |     -     |   4.96   \n",
      "----------------------------------------------------------------------\n",
      "  18    |    -    |   0.567236   |  1.142095  |   42.23  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  18    |  54.816%  |  86.760%  |  60.383%  |     62.813%     |   54.816%    |  71.905%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  18    |  71.905%  |     -     |     -     |     71.905%     |   71.905%    |  71.905%  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  19    |   10    |   0.628765   |     -     |   1.73   \n",
      "  19    |   20    |   0.695120   |     -     |   1.50   \n",
      "  19    |   30    |   0.567348   |     -     |   5.93   \n",
      "  19    |   40    |   0.388347   |     -     |   1.60   \n",
      "  19    |   50    |   0.542981   |     -     |   5.85   \n",
      "  19    |   60    |   0.341235   |     -     |   1.50   \n",
      "  19    |   70    |   0.520477   |     -     |   5.82   \n",
      "  19    |   80    |   0.410636   |     -     |   1.51   \n",
      "  19    |   90    |   0.504536   |     -     |   5.96   \n",
      "  19    |   100   |   0.470566   |     -     |   1.54   \n",
      "  19    |   104   |   0.169661   |     -     |   4.88   \n",
      "----------------------------------------------------------------------\n",
      "  19    |    -    |   0.500072   |  1.320641  |   42.24  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  19    |  50.206%  |  87.164%  |  57.632%  |     58.844%     |   50.206%    |  66.190%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  19    |  66.190%  |     -     |     -     |     66.190%     |   66.190%    |  66.190%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  20    |   10    |   0.336207   |     -     |   1.75   \n",
      "  20    |   20    |   0.552569   |     -     |   1.57   \n",
      "  20    |   30    |   0.336818   |     -     |   5.87   \n",
      "  20    |   40    |   0.193214   |     -     |   1.58   \n",
      "  20    |   50    |   0.279867   |     -     |   5.99   \n",
      "  20    |   60    |   0.538480   |     -     |   1.61   \n",
      "  20    |   70    |   0.525566   |     -     |   5.84   \n",
      "  20    |   80    |   0.506815   |     -     |   1.60   \n",
      "  20    |   90    |   0.590873   |     -     |   5.88   \n",
      "  20    |   100   |   0.528780   |     -     |   1.56   \n",
      "  20    |   104   |   0.391332   |     -     |   4.87   \n",
      "----------------------------------------------------------------------\n",
      "  20    |    -    |   0.440321   |  1.377298  |   42.40  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  20    |  49.989%  |  87.260%  |  59.294%  |     59.142%     |   49.989%    |  67.143%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  20    |  67.143%  |     -     |     -     |     67.143%     |   67.143%    |  67.143%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  21    |   10    |   0.944412   |     -     |   1.79   \n",
      "  21    |   20    |   0.853641   |     -     |   1.55   \n",
      "  21    |   30    |   0.443495   |     -     |   5.85   \n",
      "  21    |   40    |   0.581510   |     -     |   1.48   \n",
      "  21    |   50    |   0.396843   |     -     |   5.83   \n",
      "  21    |   60    |   0.468167   |     -     |   1.55   \n",
      "  21    |   70    |   0.498426   |     -     |   6.49   \n",
      "  21    |   80    |   0.288069   |     -     |   1.74   \n",
      "  21    |   90    |   0.337899   |     -     |   6.38   \n",
      "  21    |   100   |   0.547172   |     -     |   1.54   \n",
      "  21    |   104   |   0.553030   |     -     |   5.11   \n",
      "Epoch    21: reducing learning rate of group 0 to 5.0000e-04.\n",
      "----------------------------------------------------------------------\n",
      "  21    |    -    |   0.545701   |  1.220653  |   44.12  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  21    |  52.992%  |  86.745%  |  59.379%  |     62.037%     |   52.992%    |  70.476%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  21    |  70.476%  |     -     |     -     |     70.476%     |   70.476%    |  70.476%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  22    |   10    |   0.664510   |     -     |   2.16   \n",
      "  22    |   20    |   0.552835   |     -     |   1.89   \n",
      "  22    |   30    |   0.333682   |     -     |   6.15   \n",
      "  22    |   40    |   0.357860   |     -     |   1.59   \n",
      "  22    |   50    |   0.282987   |     -     |   6.36   \n",
      "  22    |   60    |   0.570817   |     -     |   1.66   \n",
      "  22    |   70    |   0.325180   |     -     |   6.88   \n",
      "  22    |   80    |   0.351802   |     -     |   1.56   \n",
      "  22    |   90    |   0.236823   |     -     |   5.79   \n",
      "  22    |   100   |   0.172993   |     -     |   1.50   \n",
      "  22    |   104   |   0.335330   |     -     |   5.08   \n",
      "----------------------------------------------------------------------\n",
      "  22    |    -    |   0.389430   |  1.117315  |   45.19  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  22    |  55.376%  |  87.782%  |  61.385%  |     66.733%     |   55.376%    |  71.548%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  22    |  71.548%  |     -     |     -     |     71.548%     |   71.548%    |  71.548%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  23    |   10    |   0.309856   |     -     |   1.71   \n",
      "  23    |   20    |   0.585078   |     -     |   1.56   \n",
      "  23    |   30    |   0.393103   |     -     |   5.71   \n",
      "  23    |   40    |   0.124534   |     -     |   1.53   \n",
      "  23    |   50    |   0.240922   |     -     |   6.03   \n",
      "  23    |   60    |   0.287305   |     -     |   1.65   \n",
      "  23    |   70    |   0.200818   |     -     |   5.91   \n",
      "  23    |   80    |   0.495522   |     -     |   1.58   \n",
      "  23    |   90    |   0.500553   |     -     |   5.83   \n",
      "  23    |   100   |   0.446815   |     -     |   1.53   \n",
      "  23    |   104   |   0.697775   |     -     |   4.84   \n",
      "----------------------------------------------------------------------\n",
      "  23    |    -    |   0.374481   |  1.203691  |   42.06  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  23    |  58.086%  |  87.682%  |  61.393%  |     67.057%     |   58.086%    |  72.381%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  23    |  72.381%  |     -     |     -     |     72.381%     |   72.381%    |  72.381%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  24    |   10    |   0.469698   |     -     |   1.92   \n",
      "  24    |   20    |   0.483807   |     -     |   1.60   \n",
      "  24    |   30    |   0.385352   |     -     |   6.30   \n",
      "  24    |   40    |   0.359537   |     -     |   1.48   \n",
      "  24    |   50    |   0.340824   |     -     |   5.94   \n",
      "  24    |   60    |   0.387171   |     -     |   1.57   \n",
      "  24    |   70    |   0.252270   |     -     |   5.84   \n",
      "  24    |   80    |   0.277260   |     -     |   1.70   \n",
      "  24    |   90    |   0.317730   |     -     |   6.68   \n",
      "  24    |   100   |   0.273904   |     -     |   1.61   \n",
      "  24    |   104   |   0.216307   |     -     |   5.80   \n",
      "----------------------------------------------------------------------\n",
      "  24    |    -    |   0.353947   |  1.174847  |   44.71  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  24    |  56.897%  |  88.120%  |  61.531%  |     67.048%     |   56.897%    |  71.548%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  24    |  71.548%  |     -     |     -     |     71.548%     |   71.548%    |  71.548%  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  25    |   10    |   0.541780   |     -     |   1.69   \n",
      "  25    |   20    |   0.555198   |     -     |   1.51   \n",
      "  25    |   30    |   0.473276   |     -     |   5.63   \n",
      "  25    |   40    |   0.114115   |     -     |   1.48   \n",
      "  25    |   50    |   0.175552   |     -     |   5.64   \n",
      "  25    |   60    |   0.180843   |     -     |   1.52   \n",
      "  25    |   70    |   0.251170   |     -     |   5.64   \n",
      "  25    |   80    |   0.157968   |     -     |   1.49   \n",
      "  25    |   90    |   0.326040   |     -     |   5.63   \n",
      "  25    |   100   |   0.495060   |     -     |   1.47   \n",
      "  25    |   104   |   0.185865   |     -     |   4.72   \n",
      "----------------------------------------------------------------------\n",
      "  25    |    -    |   0.326878   |  1.192616  |   40.54  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  25    |  57.097%  |  87.741%  |  61.090%  |     60.799%     |   57.097%    |  72.976%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  25    |  72.976%  |     -     |     -     |     72.976%     |   72.976%    |  72.976%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  26    |   10    |   0.616881   |     -     |   1.69   \n",
      "  26    |   20    |   0.322705   |     -     |   1.50   \n",
      "  26    |   30    |   0.343907   |     -     |   5.66   \n",
      "  26    |   40    |   0.215215   |     -     |   1.49   \n",
      "  26    |   50    |   0.302767   |     -     |   5.59   \n",
      "  26    |   60    |   0.303726   |     -     |   1.48   \n",
      "  26    |   70    |   0.125169   |     -     |   5.61   \n",
      "  26    |   80    |   0.248274   |     -     |   1.50   \n",
      "  26    |   90    |   0.282347   |     -     |   5.64   \n",
      "  26    |   100   |   0.230724   |     -     |   1.50   \n",
      "  26    |   104   |   0.204574   |     -     |   4.78   \n",
      "----------------------------------------------------------------------\n",
      "  26    |    -    |   0.301465   |  1.194705  |   40.62  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  26    |  56.592%  |  87.652%  |  60.824%  |     63.829%     |   56.592%    |  72.738%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  26    |  72.738%  |     -     |     -     |     72.738%     |   72.738%    |  72.738%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  27    |   10    |   0.445305   |     -     |   1.77   \n",
      "  27    |   20    |   0.459228   |     -     |   1.51   \n",
      "  27    |   30    |   0.227992   |     -     |   5.96   \n",
      "  27    |   40    |   0.145706   |     -     |   1.52   \n",
      "  27    |   50    |   0.172160   |     -     |   6.05   \n",
      "  27    |   60    |   0.113036   |     -     |   1.50   \n",
      "  27    |   70    |   0.158615   |     -     |   6.16   \n",
      "  27    |   80    |   0.467170   |     -     |   1.51   \n",
      "  27    |   90    |   0.263211   |     -     |   6.17   \n",
      "  27    |   100   |   0.281066   |     -     |   1.53   \n",
      "  27    |   104   |   0.195797   |     -     |   5.20   \n",
      "----------------------------------------------------------------------\n",
      "  27    |    -    |   0.274648   |  1.258893  |   43.57  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  27    |  55.181%  |  87.806%  |  60.607%  |     66.348%     |   55.181%    |  71.905%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  27    |  71.905%  |     -     |     -     |     71.905%     |   71.905%    |  71.905%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  28    |   10    |   0.498362   |     -     |   1.89   \n",
      "  28    |   20    |   0.435621   |     -     |   1.64   \n",
      "  28    |   30    |   0.139077   |     -     |   6.26   \n",
      "  28    |   40    |   0.193559   |     -     |   1.64   \n",
      "  28    |   50    |   0.224600   |     -     |   6.31   \n",
      "  28    |   60    |   0.143623   |     -     |   1.65   \n",
      "  28    |   70    |   0.165199   |     -     |   6.37   \n",
      "  28    |   80    |   0.256498   |     -     |   1.66   \n",
      "  28    |   90    |   0.224919   |     -     |   6.33   \n",
      "  28    |   100   |   0.252240   |     -     |   1.61   \n",
      "  28    |   104   |   0.230970   |     -     |   5.38   \n",
      "Epoch    28: reducing learning rate of group 0 to 2.5000e-04.\n",
      "----------------------------------------------------------------------\n",
      "  28    |    -    |   0.257300   |  1.388045  |   45.50  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  28    |  54.613%  |  87.367%  |  60.165%  |     67.388%     |   54.613%    |  71.548%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  28    |  71.548%  |     -     |     -     |     71.548%     |   71.548%    |  71.548%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  29    |   10    |   0.590876   |     -     |   1.95   \n",
      "  29    |   20    |   0.535007   |     -     |   1.72   \n",
      "  29    |   30    |   0.121993   |     -     |   6.19   \n",
      "  29    |   40    |   0.103623   |     -     |   1.47   \n",
      "  29    |   50    |   0.172431   |     -     |   5.71   \n",
      "  29    |   60    |   0.316160   |     -     |   1.48   \n",
      "  29    |   70    |   0.172290   |     -     |   5.76   \n",
      "  29    |   80    |   0.221972   |     -     |   1.50   \n",
      "  29    |   90    |   0.376433   |     -     |   6.16   \n",
      "  29    |   100   |   0.136870   |     -     |   1.62   \n",
      "  29    |   104   |   0.269014   |     -     |   5.33   \n",
      "----------------------------------------------------------------------\n",
      "  29    |    -    |   0.280226   |  1.243968  |   43.23  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  29    |  57.639%  |  87.842%  |  61.636%  |     64.108%     |   57.639%    |  73.214%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  29    |  73.214%  |     -     |     -     |     73.214%     |   73.214%    |  73.214%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  30    |   10    |   0.437332   |     -     |   1.75   \n",
      "  30    |   20    |   0.428908   |     -     |   1.50   \n",
      "  30    |   30    |   0.546397   |     -     |   5.65   \n",
      "  30    |   40    |   0.129957   |     -     |   1.47   \n",
      "  30    |   50    |   0.132192   |     -     |   5.59   \n",
      "  30    |   60    |   0.056304   |     -     |   1.48   \n",
      "  30    |   70    |   0.125286   |     -     |   5.62   \n",
      "  30    |   80    |   0.127154   |     -     |   1.47   \n",
      "  30    |   90    |   0.277082   |     -     |   5.62   \n",
      "  30    |   100   |   0.132895   |     -     |   1.48   \n",
      "  30    |   104   |   0.391310   |     -     |   4.77   \n",
      "----------------------------------------------------------------------\n",
      "  30    |    -    |   0.249400   |  1.225089  |   40.58  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  30    |  56.576%  |  88.149%  |  61.701%  |     66.581%     |   56.576%    |  72.738%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  30    |  72.738%  |     -     |     -     |     72.738%     |   72.738%    |  72.738%  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoint/textcnn_aug/k1 model cleaned\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   10    |   5.448909   |     -     |   1.72   \n",
      "   1    |   20    |   3.346522   |     -     |   1.50   \n",
      "   1    |   30    |   2.718800   |     -     |   5.72   \n",
      "   1    |   40    |   2.575842   |     -     |   1.47   \n",
      "   1    |   50    |   2.429005   |     -     |   5.62   \n",
      "   1    |   60    |   2.408510   |     -     |   1.47   \n",
      "   1    |   70    |   2.409909   |     -     |   5.68   \n",
      "   1    |   80    |   2.289253   |     -     |   1.48   \n",
      "   1    |   90    |   2.021042   |     -     |   5.65   \n",
      "   1    |   100   |   1.907148   |     -     |   1.46   \n",
      "   1    |   104   |   2.169859   |     -     |   4.74   \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   2.785363   |  1.928305  |   40.68  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   1    |  18.359%  |  68.356%  |  28.819%  |     26.536%     |   18.359%    |  39.524%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   1    |  39.524%  |     -     |     -     |     39.524%     |   39.524%    |  39.524%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   2    |   10    |   4.311298   |     -     |   1.71   \n",
      "   2    |   20    |   2.589588   |     -     |   1.49   \n",
      "   2    |   30    |   2.148448   |     -     |   5.69   \n",
      "   2    |   40    |   1.688606   |     -     |   1.50   \n",
      "   2    |   50    |   1.672408   |     -     |   5.61   \n",
      "   2    |   60    |   1.579911   |     -     |   1.49   \n",
      "   2    |   70    |   1.908231   |     -     |   5.66   \n",
      "   2    |   80    |   1.891549   |     -     |   1.50   \n",
      "   2    |   90    |   1.751119   |     -     |   5.68   \n",
      "   2    |   100   |   1.630990   |     -     |   1.48   \n",
      "   2    |   104   |   1.524510   |     -     |   4.79   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   2.135873   |  1.633200  |   40.74  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   2    |  33.058%  |  74.683%  |  39.917%  |     32.780%     |   33.058%    |  49.643%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   2    |  49.643%  |     -     |     -     |     49.643%     |   49.643%    |  49.643%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   3    |   10    |   1.650407   |     -     |   1.70   \n",
      "   3    |   20    |   1.494925   |     -     |   1.51   \n",
      "   3    |   30    |   1.790087   |     -     |   5.63   \n",
      "   3    |   40    |   1.221677   |     -     |   1.48   \n",
      "   3    |   50    |   1.657280   |     -     |   5.62   \n",
      "   3    |   60    |   1.349373   |     -     |   1.47   \n",
      "   3    |   70    |   1.266328   |     -     |   5.64   \n",
      "   3    |   80    |   1.703106   |     -     |   1.50   \n",
      "   3    |   90    |   1.925657   |     -     |   5.60   \n",
      "   3    |   100   |   1.502283   |     -     |   1.49   \n",
      "   3    |   104   |   2.200526   |     -     |   4.71   \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   1.596767   |  1.429774  |   40.48  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   3    |  35.112%  |  77.472%  |  47.304%  |     41.739%     |   35.112%    |  58.571%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   3    |  58.571%  |     -     |     -     |     58.571%     |   58.571%    |  58.571%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   4    |   10    |   1.662187   |     -     |   1.79   \n",
      "   4    |   20    |   1.425825   |     -     |   1.51   \n",
      "   4    |   30    |   1.442058   |     -     |   5.63   \n",
      "   4    |   40    |   1.713931   |     -     |   1.47   \n",
      "   4    |   50    |   1.535063   |     -     |   5.63   \n",
      "   4    |   60    |   1.175004   |     -     |   1.47   \n",
      "   4    |   70    |   1.370113   |     -     |   5.59   \n",
      "   4    |   80    |   1.339294   |     -     |   1.49   \n",
      "   4    |   90    |   1.614625   |     -     |   5.67   \n",
      "   4    |   100   |   1.296090   |     -     |   1.48   \n",
      "   4    |   104   |   1.381473   |     -     |   4.73   \n",
      "----------------------------------------------------------------------\n",
      "   4    |    -    |   1.470481   |  1.424934  |   40.59  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   4    |  38.806%  |  77.983%  |  50.585%  |     52.098%     |   38.806%    |  56.786%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   4    |  56.786%  |     -     |     -     |     56.786%     |   56.786%    |  56.786%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   5    |   10    |   1.587756   |     -     |   1.69   \n",
      "   5    |   20    |   1.153560   |     -     |   1.47   \n",
      "   5    |   30    |   1.232906   |     -     |   5.62   \n",
      "   5    |   40    |   1.173308   |     -     |   1.49   \n",
      "   5    |   50    |   1.130014   |     -     |   5.68   \n",
      "   5    |   60    |   1.162070   |     -     |   1.48   \n",
      "   5    |   70    |   1.106427   |     -     |   5.65   \n",
      "   5    |   80    |   1.360422   |     -     |   1.51   \n",
      "   5    |   90    |   1.217554   |     -     |   5.61   \n",
      "   5    |   100   |   0.985406   |     -     |   1.46   \n",
      "   5    |   104   |   1.085904   |     -     |   4.73   \n",
      "----------------------------------------------------------------------\n",
      "   5    |    -    |   1.221400   |  1.319066  |   40.52  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   5    |  50.902%  |  79.826%  |  55.987%  |     55.658%     |   50.902%    |  63.333%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   5    |  63.333%  |     -     |     -     |     63.333%     |   63.333%    |  63.333%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   6    |   10    |   1.217421   |     -     |   1.72   \n",
      "   6    |   20    |   1.068624   |     -     |   1.49   \n",
      "   6    |   30    |   0.998738   |     -     |   5.64   \n",
      "   6    |   40    |   1.242361   |     -     |   1.49   \n",
      "   6    |   50    |   1.532369   |     -     |   5.65   \n",
      "   6    |   60    |   1.347404   |     -     |   1.49   \n",
      "   6    |   70    |   0.966510   |     -     |   5.64   \n",
      "   6    |   80    |   0.990214   |     -     |   1.47   \n",
      "   6    |   90    |   0.976106   |     -     |   5.65   \n",
      "   6    |   100   |   1.214895   |     -     |   1.46   \n",
      "   6    |   104   |   1.215036   |     -     |   4.76   \n",
      "----------------------------------------------------------------------\n",
      "   6    |    -    |   1.169461   |  1.136043  |   40.71  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   6    |  51.959%  |  81.333%  |  61.311%  |     62.656%     |   51.959%    |  67.024%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   6    |  67.024%  |     -     |     -     |     67.024%     |   67.024%    |  67.024%  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   7    |   10    |   0.985310   |     -     |   1.77   \n",
      "   7    |   20    |   1.195302   |     -     |   1.48   \n",
      "   7    |   30    |   1.282200   |     -     |   5.64   \n",
      "   7    |   40    |   0.896012   |     -     |   1.48   \n",
      "   7    |   50    |   0.954022   |     -     |   5.66   \n",
      "   7    |   60    |   1.168383   |     -     |   1.49   \n",
      "   7    |   70    |   0.965996   |     -     |   5.64   \n",
      "   7    |   80    |   1.592232   |     -     |   1.49   \n",
      "   7    |   90    |   1.247428   |     -     |   5.62   \n",
      "   7    |   100   |   0.811402   |     -     |   1.50   \n",
      "   7    |   104   |   1.153562   |     -     |   4.72   \n",
      "----------------------------------------------------------------------\n",
      "   7    |    -    |   1.120985   |  1.076969  |   40.66  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   7    |  57.882%  |  83.083%  |  66.719%  |     67.723%     |   57.882%    |  70.238%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   7    |  70.238%  |     -     |     -     |     70.238%     |   70.238%    |  70.238%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   8    |   10    |   0.956309   |     -     |   1.72   \n",
      "   8    |   20    |   0.918459   |     -     |   1.46   \n",
      "   8    |   30    |   1.103713   |     -     |   5.59   \n",
      "   8    |   40    |   1.208319   |     -     |   1.49   \n",
      "   8    |   50    |   0.849159   |     -     |   5.58   \n",
      "   8    |   60    |   1.194169   |     -     |   1.47   \n",
      "   8    |   70    |   0.913999   |     -     |   5.62   \n",
      "   8    |   80    |   0.820377   |     -     |   1.48   \n",
      "   8    |   90    |   0.640010   |     -     |   5.64   \n",
      "   8    |   100   |   0.828855   |     -     |   1.49   \n",
      "   8    |   104   |   0.811682   |     -     |   4.72   \n",
      "----------------------------------------------------------------------\n",
      "   8    |    -    |   0.947468   |  1.301423  |   40.42  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   8    |  51.225%  |  82.230%  |  62.617%  |     67.765%     |   51.225%    |  62.738%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   8    |  62.738%  |     -     |     -     |     62.738%     |   62.738%    |  62.738%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   9    |   10    |   1.230983   |     -     |   1.72   \n",
      "   9    |   20    |   1.616022   |     -     |   1.48   \n",
      "   9    |   30    |   1.072279   |     -     |   5.62   \n",
      "   9    |   40    |   0.752227   |     -     |   1.47   \n",
      "   9    |   50    |   0.869753   |     -     |   5.61   \n",
      "   9    |   60    |   0.926302   |     -     |   1.47   \n",
      "   9    |   70    |   0.781081   |     -     |   5.59   \n",
      "   9    |   80    |   1.016341   |     -     |   1.50   \n",
      "   9    |   90    |   1.232795   |     -     |   5.63   \n",
      "   9    |   100   |   0.982304   |     -     |   1.48   \n",
      "   9    |   104   |   0.926702   |     -     |   4.76   \n",
      "----------------------------------------------------------------------\n",
      "   9    |    -    |   1.055179   |  1.094455  |   40.46  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   9    |  56.606%  |  83.001%  |  65.170%  |     62.652%     |   56.606%    |  68.452%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   9    |  68.452%  |     -     |     -     |     68.452%     |   68.452%    |  68.452%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  10    |   10    |   1.141947   |     -     |   1.75   \n",
      "  10    |   20    |   1.255615   |     -     |   1.50   \n",
      "  10    |   30    |   0.785147   |     -     |   5.67   \n",
      "  10    |   40    |   0.887115   |     -     |   1.48   \n",
      "  10    |   50    |   0.671187   |     -     |   5.63   \n",
      "  10    |   60    |   0.799590   |     -     |   1.65   \n",
      "  10    |   70    |   0.826422   |     -     |   5.59   \n",
      "  10    |   80    |   0.792930   |     -     |   1.51   \n",
      "  10    |   90    |   0.751919   |     -     |   6.07   \n",
      "  10    |   100   |   0.882267   |     -     |   1.59   \n",
      "  10    |   104   |   1.003349   |     -     |   4.96   \n",
      "----------------------------------------------------------------------\n",
      "  10    |    -    |   0.895161   |  1.149380  |   41.82  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  10    |  59.573%  |  83.169%  |  69.411%  |     67.557%     |   59.573%    |  70.476%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  10    |  70.476%  |     -     |     -     |     70.476%     |   70.476%    |  70.476%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  11    |   10    |   0.873911   |     -     |   1.75   \n",
      "  11    |   20    |   1.058024   |     -     |   1.51   \n",
      "  11    |   30    |   0.648417   |     -     |   5.86   \n",
      "  11    |   40    |   0.723718   |     -     |   1.50   \n",
      "  11    |   50    |   0.723118   |     -     |   5.71   \n",
      "  11    |   60    |   0.801694   |     -     |   1.52   \n",
      "  11    |   70    |   0.528727   |     -     |   6.17   \n",
      "  11    |   80    |   0.751487   |     -     |   1.53   \n",
      "  11    |   90    |   0.843716   |     -     |   5.93   \n",
      "  11    |   100   |   0.732038   |     -     |   1.80   \n",
      "  11    |   104   |   0.707619   |     -     |   5.02   \n",
      "----------------------------------------------------------------------\n",
      "  11    |    -    |   0.774547   |  1.108311  |   42.97  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  11    |  59.335%  |  82.920%  |  68.997%  |     71.842%     |   59.335%    |  69.286%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  11    |  69.286%  |     -     |     -     |     69.286%     |   69.286%    |  69.286%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  12    |   10    |   1.024038   |     -     |   1.74   \n",
      "  12    |   20    |   1.020261   |     -     |   1.50   \n",
      "  12    |   30    |   0.673049   |     -     |   5.70   \n",
      "  12    |   40    |   0.645750   |     -     |   1.62   \n",
      "  12    |   50    |   0.923919   |     -     |   6.08   \n",
      "  12    |   60    |   0.794240   |     -     |   1.48   \n",
      "  12    |   70    |   0.869103   |     -     |   5.64   \n",
      "  12    |   80    |   0.977736   |     -     |   1.50   \n",
      "  12    |   90    |   0.698917   |     -     |   5.64   \n",
      "  12    |   100   |   0.479261   |     -     |   1.48   \n",
      "  12    |   104   |   1.067561   |     -     |   4.79   \n",
      "----------------------------------------------------------------------\n",
      "  12    |    -    |   0.830356   |  1.045963  |   41.38  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  12    |  66.067%  |  83.634%  |  71.505%  |     71.549%     |   66.067%    |  71.190%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  12    |  71.190%  |     -     |     -     |     71.190%     |   71.190%    |  71.190%  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  13    |   10    |   0.986295   |     -     |   1.77   \n",
      "  13    |   20    |   0.636493   |     -     |   1.51   \n",
      "  13    |   30    |   0.622460   |     -     |   5.64   \n",
      "  13    |   40    |   0.769189   |     -     |   1.50   \n",
      "  13    |   50    |   0.703505   |     -     |   5.68   \n",
      "  13    |   60    |   0.764656   |     -     |   1.48   \n",
      "  13    |   70    |   0.554478   |     -     |   5.69   \n",
      "  13    |   80    |   0.726883   |     -     |   1.51   \n",
      "  13    |   90    |   0.705398   |     -     |   5.92   \n",
      "  13    |   100   |   0.775631   |     -     |   1.63   \n",
      "  13    |   104   |   0.725965   |     -     |   4.75   \n",
      "----------------------------------------------------------------------\n",
      "  13    |    -    |   0.734039   |  1.054610  |   41.52  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  13    |  66.833%  |  83.379%  |  71.598%  |     73.772%     |   66.833%    |  72.262%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  13    |  72.262%  |     -     |     -     |     72.262%     |   72.262%    |  72.262%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  14    |   10    |   0.673153   |     -     |   1.79   \n",
      "  14    |   20    |   0.656880   |     -     |   1.53   \n",
      "  14    |   30    |   0.473348   |     -     |   5.67   \n",
      "  14    |   40    |   0.614370   |     -     |   1.48   \n",
      "  14    |   50    |   0.593549   |     -     |   5.65   \n",
      "  14    |   60    |   0.503941   |     -     |   1.50   \n",
      "  14    |   70    |   0.759841   |     -     |   5.72   \n",
      "  14    |   80    |   0.850953   |     -     |   1.49   \n",
      "  14    |   90    |   0.918227   |     -     |   5.67   \n",
      "  14    |   100   |   0.349209   |     -     |   1.79   \n",
      "  14    |   104   |   0.491471   |     -     |   4.85   \n",
      "----------------------------------------------------------------------\n",
      "  14    |    -    |   0.640132   |  1.081396  |   41.40  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  14    |  60.261%  |  83.073%  |  72.097%  |     65.667%     |   60.261%    |  72.024%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  14    |  72.024%  |     -     |     -     |     72.024%     |   72.024%    |  72.024%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  15    |   10    |   0.765251   |     -     |   1.69   \n",
      "  15    |   20    |   0.771339   |     -     |   1.52   \n",
      "  15    |   30    |   0.760230   |     -     |   5.69   \n",
      "  15    |   40    |   0.672680   |     -     |   1.53   \n",
      "  15    |   50    |   0.521588   |     -     |   5.61   \n",
      "  15    |   60    |   0.748640   |     -     |   1.48   \n",
      "  15    |   70    |   0.759731   |     -     |   5.53   \n",
      "  15    |   80    |   0.813585   |     -     |   1.48   \n",
      "  15    |   90    |   0.754783   |     -     |   5.57   \n",
      "  15    |   100   |   0.608902   |     -     |   1.49   \n",
      "  15    |   104   |   1.054504   |     -     |   4.67   \n",
      "----------------------------------------------------------------------\n",
      "  15    |    -    |   0.737986   |  1.124184  |   40.41  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  15    |  61.250%  |  82.132%  |  68.894%  |     72.305%     |   61.250%    |  70.595%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  15    |  70.595%  |     -     |     -     |     70.595%     |   70.595%    |  70.595%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  16    |   10    |   1.079151   |     -     |   1.75   \n",
      "  16    |   20    |   0.831232   |     -     |   1.72   \n",
      "  16    |   30    |   0.710331   |     -     |   5.79   \n",
      "  16    |   40    |   0.881600   |     -     |   1.48   \n",
      "  16    |   50    |   0.733733   |     -     |   5.79   \n",
      "  16    |   60    |   0.550186   |     -     |   1.60   \n",
      "  16    |   70    |   0.557862   |     -     |   6.11   \n",
      "  16    |   80    |   0.745639   |     -     |   1.47   \n",
      "  16    |   90    |   0.652836   |     -     |   5.63   \n",
      "  16    |   100   |   0.304294   |     -     |   1.51   \n",
      "  16    |   104   |   0.503784   |     -     |   4.69   \n",
      "----------------------------------------------------------------------\n",
      "  16    |    -    |   0.707336   |  0.987831  |   41.71  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  16    |  67.055%  |  83.216%  |  71.669%  |     74.923%     |   67.055%    |  74.286%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  16    |  74.286%  |     -     |     -     |     74.286%     |   74.286%    |  74.286%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  17    |   10    |   0.878429   |     -     |   1.74   \n",
      "  17    |   20    |   0.810265   |     -     |   1.57   \n",
      "  17    |   30    |   0.440728   |     -     |   5.62   \n",
      "  17    |   40    |   0.582028   |     -     |   1.47   \n",
      "  17    |   50    |   0.686695   |     -     |   5.58   \n",
      "  17    |   60    |   0.662600   |     -     |   1.49   \n",
      "  17    |   70    |   0.520722   |     -     |   5.62   \n",
      "  17    |   80    |   0.402806   |     -     |   1.51   \n",
      "  17    |   90    |   0.359316   |     -     |   5.73   \n",
      "  17    |   100   |   0.403015   |     -     |   1.55   \n",
      "  17    |   104   |   0.672205   |     -     |   4.84   \n",
      "----------------------------------------------------------------------\n",
      "  17    |    -    |   0.586859   |  1.089677  |   41.04  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  17    |  64.406%  |  83.028%  |  72.189%  |     72.928%     |   64.406%    |  73.214%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  17    |  73.214%  |     -     |     -     |     73.214%     |   73.214%    |  73.214%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  18    |   10    |   0.473942   |     -     |   1.88   \n",
      "  18    |   20    |   0.699418   |     -     |   1.58   \n",
      "  18    |   30    |   0.421939   |     -     |   6.19   \n",
      "  18    |   40    |   0.482301   |     -     |   1.54   \n",
      "  18    |   50    |   0.460704   |     -     |   6.00   \n",
      "  18    |   60    |   0.663253   |     -     |   1.46   \n",
      "  18    |   70    |   0.386897   |     -     |   6.12   \n",
      "  18    |   80    |   0.529748   |     -     |   1.56   \n",
      "  18    |   90    |   0.542640   |     -     |   5.86   \n",
      "  18    |   100   |   0.436155   |     -     |   1.56   \n",
      "  18    |   104   |   0.305678   |     -     |   5.54   \n",
      "----------------------------------------------------------------------\n",
      "  18    |    -    |   0.506410   |  1.131585  |   43.88  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  18    |  63.645%  |  84.136%  |  71.577%  |     67.455%     |   63.645%    |  71.310%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  18    |  71.310%  |     -     |     -     |     71.310%     |   71.310%    |  71.310%  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  19    |   10    |   0.689589   |     -     |   1.71   \n",
      "  19    |   20    |   0.774408   |     -     |   1.48   \n",
      "  19    |   30    |   0.551916   |     -     |   6.16   \n",
      "  19    |   40    |   0.560088   |     -     |   1.74   \n",
      "  19    |   50    |   0.547460   |     -     |   6.18   \n",
      "  19    |   60    |   0.237577   |     -     |   1.56   \n",
      "  19    |   70    |   0.390466   |     -     |   6.08   \n",
      "  19    |   80    |   0.493982   |     -     |   1.49   \n",
      "  19    |   90    |   0.423881   |     -     |   6.02   \n",
      "  19    |   100   |   0.820175   |     -     |   1.53   \n",
      "  19    |   104   |   0.615769   |     -     |   5.12   \n",
      "Epoch    19: reducing learning rate of group 0 to 5.0000e-04.\n",
      "----------------------------------------------------------------------\n",
      "  19    |    -    |   0.558155   |  1.039981  |   43.43  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  19    |  65.245%  |  83.630%  |  71.942%  |     71.748%     |   65.245%    |  72.857%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  19    |  72.857%  |     -     |     -     |     72.857%     |   72.857%    |  72.857%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  20    |   10    |   0.588736   |     -     |   2.11   \n",
      "  20    |   20    |   0.717680   |     -     |   3.00   \n",
      "  20    |   30    |   0.262951   |     -     |   10.60  \n",
      "  20    |   40    |   0.420904   |     -     |   2.60   \n",
      "  20    |   50    |   0.617232   |     -     |   9.93   \n",
      "  20    |   60    |   0.385551   |     -     |   3.71   \n",
      "  20    |   70    |   0.428283   |     -     |   11.05  \n",
      "  20    |   80    |   0.314389   |     -     |   3.43   \n",
      "  20    |   90    |   0.389335   |     -     |   6.51   \n",
      "  20    |   100   |   0.208505   |     -     |   1.55   \n",
      "  20    |   104   |   0.283369   |     -     |   4.98   \n",
      "----------------------------------------------------------------------\n",
      "  20    |    -    |   0.433249   |  1.084796  |   63.86  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  20    |  65.253%  |  83.249%  |  70.765%  |     72.383%     |   65.253%    |  73.452%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  20    |  73.452%  |     -     |     -     |     73.452%     |   73.452%    |  73.452%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  21    |   10    |   0.821369   |     -     |   1.72   \n",
      "  21    |   20    |   1.074351   |     -     |   1.47   \n",
      "  21    |   30    |   0.167478   |     -     |   5.87   \n",
      "  21    |   40    |   0.406377   |     -     |   1.59   \n",
      "  21    |   50    |   0.220264   |     -     |   5.88   \n",
      "  21    |   60    |   0.227308   |     -     |   1.56   \n",
      "  21    |   70    |   0.363736   |     -     |   5.65   \n",
      "  21    |   80    |   0.442669   |     -     |   1.48   \n",
      "  21    |   90    |   0.164422   |     -     |   6.19   \n",
      "  21    |   100   |   0.322674   |     -     |   1.51   \n",
      "  21    |   104   |   0.300784   |     -     |   4.79   \n",
      "----------------------------------------------------------------------\n",
      "  21    |    -    |   0.424336   |  1.040215  |   41.84  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  21    |  65.498%  |  84.175%  |  71.369%  |     69.907%     |   65.498%    |  73.571%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "  21    |  73.571%  |     -     |     -     |     73.571%     |   73.571%    |  73.571%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "./checkpoint/textcnn_aug/k2 model cleaned\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   10    |   5.066317   |     -     |   2.03   \n",
      "   1    |   20    |   3.393170   |     -     |   1.61   \n",
      "   1    |   30    |   2.741648   |     -     |   6.60   \n",
      "   1    |   40    |   2.658074   |     -     |   1.54   \n",
      "   1    |   50    |   2.460109   |     -     |   10.58  \n",
      "   1    |   60    |   2.291328   |     -     |   4.33   \n",
      "   1    |   70    |   2.380772   |     -     |   11.14  \n",
      "   1    |   80    |   2.164359   |     -     |   2.84   \n",
      "   1    |   90    |   2.081161   |     -     |   12.86  \n",
      "   1    |   100   |   2.116557   |     -     |   3.83   \n",
      "   1    |   104   |   2.000350   |     -     |   9.31   \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   2.755795   |  2.107860  |   73.47  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   1    |  19.275%  |  74.831%  |  27.114%  |     19.383%     |   19.275%    |  40.357%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   1    |  40.357%  |     -     |     -     |     40.357%     |   40.357%    |  40.357%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   2    |   10    |   4.003892   |     -     |   3.17   \n",
      "   2    |   20    |   3.134686   |     -     |   3.84   \n",
      "   2    |   30    |   1.653149   |     -     |   11.02  \n",
      "   2    |   40    |   1.946838   |     -     |   3.41   \n",
      "   2    |   50    |   1.914789   |     -     |   11.17  \n",
      "   2    |   60    |   1.853968   |     -     |   3.06   \n",
      "   2    |   70    |   1.693976   |     -     |   10.93  \n",
      "   2    |   80    |   1.727491   |     -     |   3.35   \n",
      "   2    |   90    |   1.477815   |     -     |   12.07  \n",
      "   2    |   100   |   1.605305   |     -     |   3.43   \n",
      "   2    |   104   |   1.404135   |     -     |   8.20   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   2.112880   |  1.637979  |   80.73  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   2    |  28.075%  |  81.833%  |  42.378%  |     41.339%     |   28.075%    |  51.429%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   2    |  51.429%  |     -     |     -     |     51.429%     |   51.429%    |  51.429%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   3    |   10    |   2.251160   |     -     |   3.25   \n",
      "   3    |   20    |   1.758883   |     -     |   2.62   \n",
      "   3    |   30    |   1.717555   |     -     |   9.93   \n",
      "   3    |   40    |   1.665564   |     -     |   2.54   \n",
      "   3    |   50    |   1.459653   |     -     |   9.18   \n",
      "   3    |   60    |   1.163729   |     -     |   2.57   \n",
      "   3    |   70    |   1.356193   |     -     |   9.03   \n",
      "   3    |   80    |   1.661274   |     -     |   2.77   \n",
      "   3    |   90    |   1.496664   |     -     |   9.61   \n",
      "   3    |   100   |   1.650171   |     -     |   2.81   \n",
      "   3    |   104   |   1.399452   |     -     |   7.56   \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   1.631321   |  1.558778  |   69.23  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   3    |  32.357%  |  82.967%  |  46.804%  |     54.503%     |   32.357%    |  55.000%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   3    |  55.000%  |     -     |     -     |     55.000%     |   55.000%    |  55.000%  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   4    |   10    |   1.721190   |     -     |   3.06   \n",
      "   4    |   20    |   1.529012   |     -     |   2.95   \n",
      "   4    |   30    |   1.295495   |     -     |   9.29   \n",
      "   4    |   40    |   1.353530   |     -     |   2.82   \n",
      "   4    |   50    |   1.626776   |     -     |   9.53   \n",
      "   4    |   60    |   1.545698   |     -     |   2.54   \n",
      "   4    |   70    |   1.659009   |     -     |   9.31   \n",
      "   4    |   80    |   1.376158   |     -     |   2.74   \n",
      "   4    |   90    |   1.424977   |     -     |   9.82   \n",
      "   4    |   100   |   1.392891   |     -     |   2.67   \n",
      "   4    |   104   |   1.494296   |     -     |   8.34   \n",
      "----------------------------------------------------------------------\n",
      "   4    |    -    |   1.509094   |  1.387021  |   70.40  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   4    |  37.598%  |  83.205%  |  50.038%  |     49.318%     |   37.598%    |  61.310%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   4    |  61.310%  |     -     |     -     |     61.310%     |   61.310%    |  61.310%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   5    |   10    |   1.374132   |     -     |   2.98   \n",
      "   5    |   20    |   1.157146   |     -     |   4.04   \n",
      "   5    |   30    |   0.838210   |     -     |   9.20   \n",
      "   5    |   40    |   1.037764   |     -     |   2.89   \n",
      "   5    |   50    |   1.592008   |     -     |   10.58  \n",
      "   5    |   60    |   1.455800   |     -     |   2.97   \n",
      "   5    |   70    |   1.032274   |     -     |   11.19  \n",
      "   5    |   80    |   0.797757   |     -     |   3.19   \n",
      "   5    |   90    |   1.263744   |     -     |   10.89  \n",
      "   5    |   100   |   1.054776   |     -     |   2.76   \n",
      "   5    |   104   |   1.200839   |     -     |   7.86   \n",
      "----------------------------------------------------------------------\n",
      "   5    |    -    |   1.175131   |  1.320040  |   75.85  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   5    |  41.554%  |  84.124%  |  56.596%  |     51.729%     |   41.554%    |  63.214%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   5    |  63.214%  |     -     |     -     |     63.214%     |   63.214%    |  63.214%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   6    |   10    |   1.320967   |     -     |   2.82   \n",
      "   6    |   20    |   1.648827   |     -     |   3.15   \n",
      "   6    |   30    |   1.303698   |     -     |   13.07  \n",
      "   6    |   40    |   0.986382   |     -     |   2.60   \n",
      "   6    |   50    |   0.982760   |     -     |   9.11   \n",
      "   6    |   60    |   0.880657   |     -     |   2.49   \n",
      "   6    |   70    |   1.013673   |     -     |   10.58  \n",
      "   6    |   80    |   1.131180   |     -     |   2.98   \n",
      "   6    |   90    |   1.201101   |     -     |   11.60  \n",
      "   6    |   100   |   1.189980   |     -     |   4.05   \n",
      "   6    |   104   |   1.365628   |     -     |   8.39   \n",
      "----------------------------------------------------------------------\n",
      "   6    |    -    |   1.186305   |  1.463952  |   78.08  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   6    |  42.334%  |  83.671%  |  54.036%  |     53.963%     |   42.334%    |  62.262%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   6    |  62.262%  |     -     |     -     |     62.262%     |   62.262%    |  62.262%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   7    |   10    |   1.292336   |     -     |   3.71   \n",
      "   7    |   20    |   0.962808   |     -     |   3.69   \n",
      "   7    |   30    |   0.917557   |     -     |   10.59  \n",
      "   7    |   40    |   0.836525   |     -     |   2.57   \n",
      "   7    |   50    |   0.730071   |     -     |   9.92   \n",
      "   7    |   60    |   1.351431   |     -     |   2.71   \n",
      "   7    |   70    |   1.388977   |     -     |   9.10   \n",
      "   7    |   80    |   1.004702   |     -     |   2.62   \n",
      "   7    |   90    |   0.889762   |     -     |   9.36   \n",
      "   7    |   100   |   1.193879   |     -     |   2.52   \n",
      "   7    |   104   |   1.064316   |     -     |   7.66   \n",
      "----------------------------------------------------------------------\n",
      "   7    |    -    |   1.069520   |  1.171852  |   70.99  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   7    |  48.102%  |  84.694%  |  57.801%  |     51.560%     |   48.102%    |  68.214%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   7    |  68.214%  |     -     |     -     |     68.214%     |   68.214%    |  68.214%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   8    |   10    |   0.927507   |     -     |   2.96   \n",
      "   8    |   20    |   0.923849   |     -     |   2.61   \n",
      "   8    |   30    |   1.039428   |     -     |   9.22   \n",
      "   8    |   40    |   0.845770   |     -     |   2.54   \n",
      "   8    |   50    |   1.025849   |     -     |   9.20   \n",
      "   8    |   60    |   1.208115   |     -     |   2.56   \n",
      "   8    |   70    |   1.174734   |     -     |   9.24   \n",
      "   8    |   80    |   1.009960   |     -     |   2.58   \n",
      "   8    |   90    |   1.023190   |     -     |   9.38   \n",
      "   8    |   100   |   1.060095   |     -     |   2.65   \n",
      "   8    |   104   |   1.016276   |     -     |   7.57   \n",
      "----------------------------------------------------------------------\n",
      "   8    |    -    |   1.032477   |  1.148952  |   67.13  \n",
      "\n",
      "\n",
      " Epoch  | Macro Acc | Macro AUC | Macro AP  | Macro Precision | Macro Recall | Macro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   8    |  51.787%  |  84.602%  |  60.882%  |     53.277%     |   51.787%    |  68.810%  \n",
      " Epoch  | Micro Acc | Micro AUC | Micro AP  | Micro Precision | Micro Recall | Micro F1 \n",
      "------------------------------------------------------------------------------------------\n",
      "   8    |  68.810%  |     -     |     -     |     68.810%     |   68.810%    |  68.810%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   9    |   10    |   0.901168   |     -     |   2.85   \n",
      "   9    |   20    |   1.035206   |     -     |   2.53   \n",
      "   9    |   30    |   1.073643   |     -     |   8.92   \n",
      "   9    |   40    |   1.041435   |     -     |   2.82   \n",
      "   9    |   50    |   0.925601   |     -     |   10.73  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-4de7744d1c95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mfeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maug_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py36_tf23\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ClassicSolution\\iflytek_app\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'token_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (batch_size, seq_len, emb_dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'word_ids'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;31m# BatchNorm1d is applied on (N,C,L)C or (N,L)L\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         x = self.projector(x.contiguous().view(-1, x.size(-1))).view(x.size(0), x.size(1),\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=24)\n",
    "for fold,(train_index, valid_index) in enumerate(kf.split(df)):\n",
    "    train, valid = df.iloc[train_index], df.iloc[valid_index]\n",
    "\n",
    "    train_dataset = MixDataset(tp.max_seq_len, w2v, c2v, phraser, label2idx, \n",
    "                               train['name'].values, train['description'].values, train['label'].values)\n",
    "    valid_dataset = MixDataset(tp.max_seq_len, w2v, c2v, phraser, label2idx, \n",
    "                               valid['name'].values, valid['description'].values, valid['label'].values)\n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    valid_sampler = SequentialSampler(valid_dataset)\n",
    "    train_loader = DataLoader(train_dataset, sampler=train_sampler, batch_size=tp.batch_size)\n",
    "\n",
    "    valid_loader = DataLoader(valid_dataset, sampler=valid_sampler, batch_size=tp.batch_size)\n",
    "    \n",
    "    CKPT = './checkpoint/textcnn_aug/k{}'.format(fold)\n",
    "    saver = ModelSave(CKPT, continue_train=False)\n",
    "    es = EarlyStop(**tp.early_stop_params)\n",
    "    global_step = 0\n",
    "    saver.init()\n",
    "    tb = SummaryWriter(CKPT)\n",
    "    model = Textcnn(tp)\n",
    "    optimizer, scheduler = model.get_optimizer()\n",
    "    \n",
    "\n",
    "    for epoch_i in range(tp['epoch_size']):\n",
    "        aug = df_aug.loc[df_aug['index'].isin(train_index),:] #避免数据泄露只使用train部分的增强数据\n",
    "        aug = aug.groupby('index').sample(1)\n",
    "        aug_dataset = MixDataset(tp.max_seq_len, w2v, c2v, phraser, label2idx, \n",
    "                           aug['name'].values, aug['description'].values, aug['label'].values)\n",
    "        aug_sampler = RandomSampler(aug_dataset)\n",
    "        aug_loader = DataLoader(aug_dataset, sampler=aug_sampler, batch_size=tp.aug_batch_size)\n",
    "        if global_step==1:\n",
    "            print(model)\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10}  | {'Elapsed':^9}\")\n",
    "        print(\"-\"*60)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        model.train()\n",
    "        aug_iter = iter(aug_loader)\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            aug_batch = next(aug_iter)\n",
    "            global_step +=1\n",
    "            batch_counts +=1\n",
    "\n",
    "            #Forward propogate\n",
    "            model.zero_grad()\n",
    "            feature = {k:v.to(device) for k, v in list(batch.items()) + list(aug_batch.items())}\n",
    "            logits = model(feature)\n",
    "            loss = model.compute_loss(feature, logits)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Log steps for train loss logging\n",
    "            if (step % log_steps == 0 and step != 0) or (step == len(train_loader) - 1):\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "                tb.add_scalar('loss/batch_train', batch_loss / batch_counts, global_step=global_step)\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "            # Save steps for ckpt saving and dev evaluation\n",
    "            if (step % save_steps == 0 and step != 0) or (step == len(train_loader) - 1):\n",
    "                val_metrics = multi_cls_metrics(model, valid_loader, device)\n",
    "                for key, val in val_metrics.items():\n",
    "                    tb.add_scalar(f'metric/{key}', val, global_step=global_step)\n",
    "                avg_train_loss = total_loss / step\n",
    "                tb.add_scalars('loss/train_valid',{'train': avg_train_loss,\n",
    "                                                    'valid': val_metrics['val_loss']}, global_step=global_step)\n",
    "                saver(total_loss / step, val_metrics['val_loss'], epoch_i, global_step, model, optimizer, scheduler)\n",
    "\n",
    "        # On Epoch End: calcualte train & valid loss and log overall metrics\n",
    "        time_elapsed = time.time() - t0_epoch\n",
    "        val_metrics = multi_cls_metrics(model, valid_loader, device)\n",
    "        avg_train_loss = total_loss / step\n",
    "        scheduler.step(val_metrics['f1_micro'])\n",
    "        print(\"-\"*70)\n",
    "        print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_metrics['val_loss']:^10.6f} | {time_elapsed:^9.2f}\")\n",
    "        multi_cls_log(epoch_i, val_metrics)\n",
    "        print(\"\\n\")\n",
    "        if es.check(val_metrics):\n",
    "            break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c931ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_process()\n",
    "test_dataset = test_dataset = MixDataset(tp.max_seq_len, w2v, c2v, phraser, label2idx,\n",
    "                                         test['name'].values, test['description'].values)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_loader = DataLoader(test_dataset, sampler=test_sampler, batch_size=tp.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8646fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = kfold_inference(test_loader, tp, Textcnn, './checkpoint/textcnn_aug', 5, device)\n",
    "result['pred'] = result['pred_avg']\n",
    "result_process(result, label2idx, './submit/textcnn_aug_5fold_avg.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_tf23",
   "language": "python",
   "name": "py36_tf23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
