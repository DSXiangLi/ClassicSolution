{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T05:30:25.599281Z",
     "iopub.status.busy": "2022-10-16T05:30:25.598476Z",
     "iopub.status.idle": "2022-10-16T05:30:28.940031Z",
     "shell.execute_reply": "2022-10-16T05:30:28.938802Z",
     "shell.execute_reply.started": "2022-10-16T05:30:25.599243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import time \n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "## 项目folder\n",
    "from dataset import SeqMultiLabelDataset\n",
    "from process import Schema2Label \n",
    "from evaluation import extract_multilabel, multilabel_inference, multilabel_evaluation\n",
    "\n",
    "from src.dataset.converter import data_loader \n",
    "from src.train_utils import set_seed, ModelSave, get_torch_device, EarlyStop, TrainParams\n",
    "from src.models.bert import BertClassifier\n",
    "from src.metrics import multilabel_metrics, multilabel_log\n",
    "import transformers \n",
    "from transformers import BertTokenizer\n",
    "transformers.logging.set_verbosity_error()\n",
    "device = get_torch_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T05:30:28.960470Z",
     "iopub.status.busy": "2022-10-16T05:30:28.960159Z",
     "iopub.status.idle": "2022-10-16T05:30:28.968761Z",
     "shell.execute_reply": "2022-10-16T05:30:28.967795Z",
     "shell.execute_reply.started": "2022-10-16T05:30:28.960428Z"
    }
   },
   "outputs": [],
   "source": [
    "DIR = './duee/trainsample'\n",
    "schema = Schema2Label(DIR+'/duee_event_schema.json')\n",
    "tp = TrainParams(\n",
    "    log_steps = 50,\n",
    "    save_steps = 10,\n",
    "    epoch_size=20,\n",
    "    max_seq_len=400,\n",
    "    batch_size=20,\n",
    "    loss_fn=nn.BCEWithLogitsLoss(),\n",
    "    lr=5e-5,\n",
    "    weight_decay=0.0,\n",
    "    epsilon=1e-6,\n",
    "    warmup_steps=100,\n",
    "    dropout_rate=0.2,\n",
    "    gradient_clip=5.0,\n",
    "    early_stop_params = {\n",
    "        'monitor':'acc',\n",
    "        'mode':'max',\n",
    "        'min_delta': 0,\n",
    "        'patience':3,\n",
    "        'verbose':False\n",
    "    },\n",
    "    pretrain_model = 'bert-base-chinese',\n",
    "    continue_train=False,\n",
    "    label2idx = schema.event_label,\n",
    "    idx2label = {j:i for i,j in schema.event_label.items()},\n",
    "    label_size=len(schema.event_label),\n",
    "    num_layers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T05:35:37.554596Z",
     "iopub.status.busy": "2022-10-16T05:35:37.554207Z",
     "iopub.status.idle": "2022-10-16T05:35:52.500806Z",
     "shell.execute_reply": "2022-10-16T05:35:52.499843Z",
     "shell.execute_reply.started": "2022-10-16T05:35:37.554563Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(tp.pretrain_model, do_lower_case=True)\n",
    "train_dataset = SeqMultiLabelDataset(data_loader(DIR+'/train_event.txt'),\n",
    "                                tokenizer, tp.max_seq_len, tp.label2idx)\n",
    "valid_dataset = SeqMultiLabelDataset(data_loader(DIR+'/valid_event.txt'), \n",
    "                                tokenizer, tp.max_seq_len,  tp.label2idx)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "valid_sampler = SequentialSampler(valid_dataset)\n",
    "train_loader = DataLoader(train_dataset, sampler=train_sampler, batch_size=tp.batch_size)\n",
    "valid_loader = DataLoader(valid_dataset, sampler=valid_sampler, batch_size=tp.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T05:38:10.455410Z",
     "iopub.status.busy": "2022-10-16T05:38:10.455048Z",
     "iopub.status.idle": "2022-10-16T05:38:46.219533Z",
     "shell.execute_reply": "2022-10-16T05:38:46.218552Z",
     "shell.execute_reply.started": "2022-10-16T05:38:10.455380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: [Errno 2] No such file or directory: './checkpoint/event' not exists\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576e04973b664564b6c3920bca851e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/393M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tp.update({'num_train_steps': int(len(train_loader)*tp.epoch_size)})\n",
    "\n",
    "CKPT = './checkpoint/event'\n",
    "saver = ModelSave(CKPT, continue_train=False)\n",
    "saver.init()\n",
    "es = EarlyStop(**tp.early_stop_params)\n",
    "global_step = 0\n",
    "tb = SummaryWriter(CKPT)\n",
    "\n",
    "model = BertClassifier(tp)\n",
    "model.to(device)\n",
    "optimizer, scheduler = model.get_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T05:38:46.221644Z",
     "iopub.status.busy": "2022-10-16T05:38:46.221257Z",
     "iopub.status.idle": "2022-10-16T08:14:19.606872Z",
     "shell.execute_reply": "2022-10-16T08:14:19.605671Z",
     "shell.execute_reply.started": "2022-10-16T05:38:46.221605Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   1    |   50    |   0.559048   |     -     |   41.31  \n",
      "   1    |   100   |   0.254757   |     -     |   39.53  \n",
      "   1    |   150   |   0.128271   |     -     |   39.56  \n",
      "   1    |   200   |   0.100548   |     -     |   39.54  \n",
      "   1    |   250   |   0.089285   |     -     |   39.50  \n",
      "   1    |   300   |   0.084674   |     -     |   39.60  \n",
      "   1    |   350   |   0.079161   |     -     |   39.58  \n",
      "   1    |   400   |   0.074094   |     -     |   39.55  \n",
      "   1    |   450   |   0.069883   |     -     |   39.56  \n",
      "   1    |   500   |   0.066074   |     -     |   39.52  \n",
      "   1    |   550   |   0.060109   |     -     |   39.52  \n",
      "   1    |   595   |   0.055112   |     -     |   35.16  \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.136696   |  0.051166  |  471.94  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   1    | 98.675%  |  97.409%   |  22.774%  |  36.917%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   2    |   50    |   0.049582   |     -     |   40.28  \n",
      "   2    |   100   |   0.048218   |     -     |   39.49  \n",
      "   2    |   150   |   0.044642   |     -     |   39.55  \n",
      "   2    |   200   |   0.041795   |     -     |   39.54  \n",
      "   2    |   250   |   0.038298   |     -     |   39.55  \n",
      "   2    |   300   |   0.035986   |     -     |   39.59  \n",
      "   2    |   350   |   0.033740   |     -     |   39.53  \n",
      "   2    |   400   |   0.030774   |     -     |   39.52  \n",
      "   2    |   450   |   0.031636   |     -     |   39.61  \n",
      "   2    |   500   |   0.029088   |     -     |   39.53  \n",
      "   2    |   550   |   0.026019   |     -     |   39.53  \n",
      "   2    |   595   |   0.025797   |     -     |   35.18  \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.036469   |  0.023915  |  470.90  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   2    | 99.270%  |  96.822%   |  59.055%  |  73.363%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   3    |   50    |   0.023667   |     -     |   40.31  \n",
      "   3    |   100   |   0.022287   |     -     |   39.56  \n",
      "   3    |   150   |   0.022900   |     -     |   39.59  \n",
      "   3    |   200   |   0.021205   |     -     |   39.50  \n",
      "   3    |   250   |   0.019709   |     -     |   39.59  \n",
      "   3    |   300   |   0.018821   |     -     |   39.56  \n",
      "   3    |   350   |   0.019309   |     -     |   39.57  \n",
      "   3    |   400   |   0.018611   |     -     |   39.59  \n",
      "   3    |   450   |   0.017512   |     -     |   39.52  \n",
      "   3    |   500   |   0.017061   |     -     |   39.49  \n",
      "   3    |   550   |   0.016879   |     -     |   39.61  \n",
      "   3    |   595   |   0.016289   |     -     |   35.18  \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   0.019588   |  0.015706  |  471.06  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   3    | 99.551%  |  96.841%   |  76.136%  |  85.249%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   4    |   50    |   0.015013   |     -     |   40.37  \n",
      "   4    |   100   |   0.013725   |     -     |   39.57  \n",
      "   4    |   150   |   0.012874   |     -     |   39.57  \n",
      "   4    |   200   |   0.013215   |     -     |   39.51  \n",
      "   4    |   250   |   0.012063   |     -     |   39.53  \n",
      "   4    |   300   |   0.012875   |     -     |   39.53  \n",
      "   4    |   350   |   0.013260   |     -     |   39.55  \n",
      "   4    |   400   |   0.013033   |     -     |   39.53  \n",
      "   4    |   450   |   0.012274   |     -     |   39.49  \n",
      "   4    |   500   |   0.011519   |     -     |   39.61  \n",
      "   4    |   550   |   0.010768   |     -     |   39.56  \n",
      "   4    |   595   |   0.011835   |     -     |   35.18  \n",
      "----------------------------------------------------------------------\n",
      "   4    |    -    |   0.012737   |  0.011689  |  471.02  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   4    | 99.749%  |  95.953%   |  89.037%  |  92.366%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   5    |   50    |   0.009261   |     -     |   40.39  \n",
      "   5    |   100   |   0.009783   |     -     |   39.60  \n",
      "   5    |   150   |   0.010375   |     -     |   39.55  \n",
      "   5    |   200   |   0.010053   |     -     |   39.54  \n",
      "   5    |   250   |   0.009158   |     -     |   39.61  \n",
      "   5    |   300   |   0.009275   |     -     |   39.54  \n",
      "   5    |   350   |   0.008520   |     -     |   39.52  \n",
      "   5    |   400   |   0.008441   |     -     |   39.59  \n",
      "   5    |   450   |   0.008261   |     -     |   39.60  \n",
      "   5    |   500   |   0.008080   |     -     |   39.53  \n",
      "   5    |   550   |   0.008510   |     -     |   39.58  \n",
      "   5    |   595   |   0.008464   |     -     |   35.19  \n",
      "----------------------------------------------------------------------\n",
      "   5    |    -    |   0.009035   |  0.009733  |  471.25  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   5    | 99.756%  |  95.909%   |  89.461%  |  92.573%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   6    |   50    |   0.007452   |     -     |   40.52  \n",
      "   6    |   100   |   0.007196   |     -     |   39.59  \n",
      "   6    |   150   |   0.008015   |     -     |   39.65  \n",
      "   6    |   200   |   0.007170   |     -     |   39.61  \n",
      "   6    |   250   |   0.007280   |     -     |   39.63  \n",
      "   6    |   300   |   0.006443   |     -     |   39.57  \n",
      "   6    |   350   |   0.006865   |     -     |   39.53  \n",
      "   6    |   400   |   0.006459   |     -     |   39.57  \n",
      "   6    |   450   |   0.006623   |     -     |   39.66  \n",
      "   6    |   500   |   0.006277   |     -     |   39.58  \n",
      "   6    |   550   |   0.006169   |     -     |   39.59  \n",
      "   6    |   595   |   0.006022   |     -     |   35.17  \n",
      "----------------------------------------------------------------------\n",
      "   6    |    -    |   0.006850   |  0.008986  |  471.69  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   6    | 99.782%  |  95.169%   |  91.884%  |  93.498%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   7    |   50    |   0.006089   |     -     |   40.38  \n",
      "   7    |   100   |   0.005634   |     -     |   39.54  \n",
      "   7    |   150   |   0.004881   |     -     |   39.61  \n",
      "   7    |   200   |   0.005235   |     -     |   39.56  \n",
      "   7    |   250   |   0.004950   |     -     |   39.56  \n",
      "   7    |   300   |   0.005382   |     -     |   39.59  \n",
      "   7    |   350   |   0.005202   |     -     |   39.58  \n",
      "   7    |   400   |   0.005064   |     -     |   39.63  \n",
      "   7    |   450   |   0.005179   |     -     |   39.60  \n",
      "   7    |   500   |   0.005417   |     -     |   39.60  \n",
      "   7    |   550   |   0.005008   |     -     |   39.57  \n",
      "   7    |   595   |   0.005498   |     -     |   35.18  \n",
      "----------------------------------------------------------------------\n",
      "   7    |    -    |   0.005303   |  0.007583  |  471.41  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   7    | 99.812%  |  96.108%   |  92.732%  |  94.390%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   8    |   50    |   0.004494   |     -     |   40.43  \n",
      "   8    |   100   |   0.004156   |     -     |   39.57  \n",
      "   8    |   150   |   0.004113   |     -     |   39.64  \n",
      "   8    |   200   |   0.004195   |     -     |   39.62  \n",
      "   8    |   250   |   0.004188   |     -     |   39.62  \n",
      "   8    |   300   |   0.003931   |     -     |   39.58  \n",
      "   8    |   350   |   0.005337   |     -     |   39.56  \n",
      "   8    |   400   |   0.004221   |     -     |   39.63  \n",
      "   8    |   450   |   0.004516   |     -     |   39.65  \n",
      "   8    |   500   |   0.004269   |     -     |   39.62  \n",
      "   8    |   550   |   0.003816   |     -     |   39.63  \n",
      "   8    |   595   |   0.003864   |     -     |   35.23  \n",
      "----------------------------------------------------------------------\n",
      "   8    |    -    |   0.004269   |  0.006986  |  471.79  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   8    | 99.816%  |  95.267%   |  93.882%  |  94.570%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   9    |   50    |   0.003196   |     -     |   40.38  \n",
      "   9    |   100   |   0.003214   |     -     |   39.64  \n",
      "   9    |   150   |   0.003811   |     -     |   39.65  \n",
      "   9    |   200   |   0.002934   |     -     |   39.62  \n",
      "   9    |   250   |   0.003573   |     -     |   39.60  \n",
      "   9    |   300   |   0.003401   |     -     |   39.63  \n",
      "   9    |   350   |   0.003323   |     -     |   39.64  \n",
      "   9    |   400   |   0.003828   |     -     |   39.63  \n",
      "   9    |   450   |   0.003568   |     -     |   39.66  \n",
      "   9    |   500   |   0.003579   |     -     |   39.58  \n",
      "   9    |   550   |   0.003988   |     -     |   39.69  \n",
      "   9    |   595   |   0.003489   |     -     |   35.21  \n",
      "----------------------------------------------------------------------\n",
      "   9    |    -    |   0.003497   |  0.007231  |  471.94  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   9    | 99.782%  |  94.944%   |  92.126%  |  93.514%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  10    |   50    |   0.003497   |     -     |   40.42  \n",
      "  10    |   100   |   0.002830   |     -     |   39.66  \n",
      "  10    |   150   |   0.003332   |     -     |   39.70  \n",
      "  10    |   200   |   0.003314   |     -     |   39.57  \n",
      "  10    |   250   |   0.003632   |     -     |   39.67  \n",
      "  10    |   300   |   0.003178   |     -     |   39.59  \n",
      "  10    |   350   |   0.003065   |     -     |   39.57  \n",
      "  10    |   400   |   0.003145   |     -     |   39.65  \n",
      "  10    |   450   |   0.002981   |     -     |   39.60  \n",
      "  10    |   500   |   0.003214   |     -     |   39.62  \n",
      "  10    |   550   |   0.002851   |     -     |   39.68  \n",
      "  10    |   595   |   0.002685   |     -     |   35.24  \n",
      "----------------------------------------------------------------------\n",
      "  10    |    -    |   0.003153   |  0.007001  |  471.98  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "  10    | 99.806%  |  94.740%   |  93.822%  |  94.279%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  11    |   50    |   0.002343   |     -     |   40.43  \n",
      "  11    |   100   |   0.002617   |     -     |   39.69  \n",
      "  11    |   150   |   0.002379   |     -     |   39.64  \n",
      "  11    |   200   |   0.002099   |     -     |   39.67  \n",
      "  11    |   250   |   0.002137   |     -     |   39.66  \n",
      "  11    |   300   |   0.002386   |     -     |   39.68  \n",
      "  11    |   350   |   0.002363   |     -     |   39.66  \n",
      "  11    |   400   |   0.002582   |     -     |   39.65  \n",
      "  11    |   450   |   0.002508   |     -     |   39.63  \n",
      "  11    |   500   |   0.002406   |     -     |   39.65  \n",
      "  11    |   550   |   0.002266   |     -     |   39.71  \n",
      "  11    |   595   |   0.002307   |     -     |   35.27  \n",
      "----------------------------------------------------------------------\n",
      "  11    |    -    |   0.002371   |  0.006587  |  472.34  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "  11    | 99.823%  |  95.285%   |  94.246%  |  94.762%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  12    |   50    |   0.001901   |     -     |   40.40  \n",
      "  12    |   100   |   0.002150   |     -     |   39.65  \n",
      "  12    |   150   |   0.001963   |     -     |   39.61  \n",
      "  12    |   200   |   0.001900   |     -     |   39.72  \n",
      "  12    |   250   |   0.001831   |     -     |   39.76  \n",
      "  12    |   300   |   0.002244   |     -     |   39.69  \n",
      "  12    |   350   |   0.001931   |     -     |   39.62  \n",
      "  12    |   400   |   0.001824   |     -     |   39.71  \n",
      "  12    |   450   |   0.002376   |     -     |   39.62  \n",
      "  12    |   500   |   0.002134   |     -     |   39.70  \n",
      "  12    |   550   |   0.001728   |     -     |   39.65  \n",
      "  12    |   595   |   0.001568   |     -     |   35.24  \n",
      "----------------------------------------------------------------------\n",
      "  12    |    -    |   0.001969   |  0.006150  |  472.37  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "  12    | 99.830%  |  95.030%   |  94.973%  |  95.002%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  13    |   50    |   0.001539   |     -     |   40.47  \n",
      "  13    |   100   |   0.001542   |     -     |   39.64  \n",
      "  13    |   150   |   0.002118   |     -     |   39.61  \n",
      "  13    |   200   |   0.001409   |     -     |   39.61  \n",
      "  13    |   250   |   0.001677   |     -     |   39.62  \n",
      "  13    |   300   |   0.001280   |     -     |   39.74  \n",
      "  13    |   350   |   0.001374   |     -     |   39.63  \n",
      "  13    |   400   |   0.001804   |     -     |   39.64  \n",
      "  13    |   450   |   0.001887   |     -     |   39.61  \n",
      "  13    |   500   |   0.001670   |     -     |   39.61  \n",
      "  13    |   550   |   0.001183   |     -     |   39.62  \n",
      "  13    |   595   |   0.001680   |     -     |   35.20  \n",
      "----------------------------------------------------------------------\n",
      "  13    |    -    |   0.001599   |  0.006487  |  472.00  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "  13    | 99.834%  |  94.504%   |  95.821%  |  95.158%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  14    |   50    |   0.001178   |     -     |   40.42  \n",
      "  14    |   100   |   0.001666   |     -     |   39.63  \n",
      "  14    |   150   |   0.001514   |     -     |   39.62  \n",
      "  14    |   200   |   0.001539   |     -     |   39.64  \n",
      "  14    |   250   |   0.001307   |     -     |   39.65  \n",
      "  14    |   300   |   0.001323   |     -     |   39.67  \n",
      "  14    |   350   |   0.001396   |     -     |   39.63  \n",
      "  14    |   400   |   0.001422   |     -     |   39.64  \n",
      "  14    |   450   |   0.001125   |     -     |   39.65  \n",
      "  14    |   500   |   0.001151   |     -     |   39.62  \n",
      "  14    |   550   |   0.001460   |     -     |   39.64  \n",
      "  14    |   595   |   0.001277   |     -     |   35.24  \n",
      "----------------------------------------------------------------------\n",
      "  14    |    -    |   0.001366   |  0.006567  |  472.05  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "  14    | 99.834%  |  94.504%   |  95.821%  |  95.158%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  15    |   50    |   0.001539   |     -     |   40.45  \n",
      "  15    |   100   |   0.001124   |     -     |   39.62  \n",
      "  15    |   150   |   0.000952   |     -     |   39.60  \n",
      "  15    |   200   |   0.001024   |     -     |   39.62  \n",
      "  15    |   250   |   0.001241   |     -     |   39.67  \n",
      "  15    |   300   |   0.000948   |     -     |   39.73  \n",
      "  15    |   350   |   0.001108   |     -     |   39.61  \n",
      "  15    |   400   |   0.001180   |     -     |   39.61  \n",
      "  15    |   450   |   0.001213   |     -     |   39.57  \n",
      "  15    |   500   |   0.001021   |     -     |   39.69  \n",
      "  15    |   550   |   0.001268   |     -     |   39.61  \n",
      "  15    |   595   |   0.001264   |     -     |   35.20  \n",
      "----------------------------------------------------------------------\n",
      "  15    |    -    |   0.001159   |  0.006549  |  471.98  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "  15    | 99.841%  |  94.474%   |  96.305%  |  95.381%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  16    |   50    |   0.001061   |     -     |   40.45  \n",
      "  16    |   100   |   0.001216   |     -     |   39.63  \n",
      "  16    |   150   |   0.001019   |     -     |   39.62  \n",
      "  16    |   200   |   0.000911   |     -     |   39.69  \n",
      "  16    |   250   |   0.000942   |     -     |   39.61  \n",
      "  16    |   300   |   0.000964   |     -     |   39.61  \n",
      "  16    |   350   |   0.000990   |     -     |   39.59  \n",
      "  16    |   400   |   0.001078   |     -     |   39.60  \n",
      "  16    |   450   |   0.000886   |     -     |   39.62  \n",
      "  16    |   500   |   0.000989   |     -     |   39.60  \n",
      "  16    |   550   |   0.000849   |     -     |   39.59  \n",
      "  16    |   595   |   0.000916   |     -     |   35.20  \n",
      "----------------------------------------------------------------------\n",
      "  16    |    -    |   0.000988   |  0.006405  |  471.82  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "  16    | 99.844%  |  95.072%   |  95.821%  |  95.445%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  17    |   50    |   0.000896   |     -     |   40.41  \n",
      "  17    |   100   |   0.001003   |     -     |   39.65  \n",
      "  17    |   150   |   0.000767   |     -     |   39.52  \n",
      "  17    |   200   |   0.000895   |     -     |   39.65  \n",
      "  17    |   250   |   0.000753   |     -     |   39.59  \n",
      "  17    |   300   |   0.000681   |     -     |   39.62  \n",
      "  17    |   350   |   0.000995   |     -     |   39.58  \n",
      "  17    |   400   |   0.000742   |     -     |   39.56  \n",
      "  17    |   450   |   0.000712   |     -     |   39.63  \n",
      "  17    |   500   |   0.000883   |     -     |   39.59  \n",
      "  17    |   550   |   0.000977   |     -     |   39.60  \n",
      "  17    |   595   |   0.001137   |     -     |   35.22  \n",
      "----------------------------------------------------------------------\n",
      "  17    |    -    |   0.000869   |  0.006750  |  471.61  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "  17    | 99.838%  |  94.838%   |  95.700%  |  95.267%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  18    |   50    |   0.000968   |     -     |   40.40  \n",
      "  18    |   100   |   0.000695   |     -     |   39.67  \n",
      "  18    |   150   |   0.000732   |     -     |   39.62  \n",
      "  18    |   200   |   0.000802   |     -     |   39.60  \n",
      "  18    |   250   |   0.000844   |     -     |   39.52  \n",
      "  18    |   300   |   0.000837   |     -     |   39.63  \n",
      "  18    |   350   |   0.000671   |     -     |   39.53  \n",
      "  18    |   400   |   0.000675   |     -     |   39.56  \n",
      "  18    |   450   |   0.000617   |     -     |   39.59  \n",
      "  18    |   500   |   0.000674   |     -     |   39.54  \n",
      "  18    |   550   |   0.001007   |     -     |   39.60  \n",
      "  18    |   595   |   0.000698   |     -     |   35.20  \n",
      "----------------------------------------------------------------------\n",
      "  18    |    -    |   0.000771   |  0.006715  |  471.46  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "  18    | 99.840%  |  94.844%   |  95.821%  |  95.330%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "  19    |   50    |   0.000985   |     -     |   40.41  \n",
      "  19    |   100   |   0.000627   |     -     |   39.60  \n",
      "  19    |   150   |   0.000791   |     -     |   39.57  \n",
      "  19    |   200   |   0.000983   |     -     |   39.58  \n",
      "  19    |   250   |   0.000602   |     -     |   39.54  \n",
      "  19    |   300   |   0.000618   |     -     |   39.60  \n",
      "  19    |   350   |   0.000733   |     -     |   39.60  \n",
      "  19    |   400   |   0.000622   |     -     |   39.58  \n",
      "  19    |   450   |   0.000703   |     -     |   39.58  \n",
      "  19    |   500   |   0.000625   |     -     |   39.59  \n",
      "  19    |   550   |   0.000801   |     -     |   39.58  \n",
      "  19    |   595   |   0.000519   |     -     |   35.16  \n",
      "----------------------------------------------------------------------\n",
      "  19    |    -    |   0.000721   |  0.006717  |  471.41  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "  19    | 99.841%  |  94.847%   |  95.881%  |  95.361%  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(tp['epoch_size']):\n",
    "    print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10}  | {'Elapsed':^9}\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    # Measure the elapsed time of each epoch\n",
    "    t0_epoch, t0_batch = time.time(), time.time()\n",
    "    total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        global_step +=1\n",
    "        batch_counts +=1\n",
    "\n",
    "        #Forward propogate\n",
    "        model.zero_grad()\n",
    "        feature = {k:v.to(device) for k, v in batch.items()}\n",
    "        logits = model(feature)\n",
    "        loss = model.compute_loss(feature, logits)\n",
    "        batch_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), tp.gradient_clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # Log steps for train loss logging\n",
    "        if (step % tp.log_steps == 0 and step != 0) or (step == len(train_loader) - 1):\n",
    "            time_elapsed = time.time() - t0_batch\n",
    "            print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "            tb.add_scalar('loss/batch_train', batch_loss / batch_counts, global_step=global_step)\n",
    "            batch_loss, batch_counts = 0, 0\n",
    "            t0_batch = time.time()\n",
    "\n",
    "    # On Epoch End: calcualte train & valid loss and log overall metrics\n",
    "    time_elapsed = time.time() - t0_epoch\n",
    "    val_metrics = multilabel_metrics(model, valid_loader, device)\n",
    "    avg_train_loss = total_loss / step\n",
    "\n",
    "    print(\"-\"*70)\n",
    "    print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_metrics['val_loss']:^10.6f} | {time_elapsed:^9.2f}\")\n",
    "    multilabel_log(epoch_i, val_metrics)\n",
    "    print(\"\\n\")\n",
    "    if es.check(val_metrics):\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T08:29:37.904440Z",
     "iopub.status.busy": "2022-10-16T08:29:37.904031Z",
     "iopub.status.idle": "2022-10-16T08:30:01.508552Z",
     "shell.execute_reply": "2022-10-16T08:30:01.507519Z",
     "shell.execute_reply.started": "2022-10-16T08:29:37.904408Z"
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = SeqMultiLabelDataset(data_loader(DIR+'/test_event.txt'), \n",
    "                                tokenizer, tp.max_seq_len,  tp.label2idx)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_loader = DataLoader(test_dataset, sampler=test_sampler, batch_size=tp.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T08:45:52.595873Z",
     "iopub.status.busy": "2022-10-16T08:45:52.595477Z",
     "iopub.status.idle": "2022-10-16T08:45:52.621639Z",
     "shell.execute_reply": "2022-10-16T08:45:52.620711Z",
     "shell.execute_reply.started": "2022-10-16T08:45:52.595838Z"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(DIR+'/test.csv')\n",
    "valid = pd.read_csv(DIR+\"/valid.csv\")\n",
    "pred = multilabel_inference(model, test_loader, device)\n",
    "test['prob'] = pred\n",
    "pred = multilabel_inference(model, valid_loader, device)\n",
    "valid['pred'] = pred\n",
    "valid['prob'] = valid['pred']\n",
    "valid['pred_label'] = valid['pred'].map(lambda x: extract_multilabel(x, tp.idx2label, 0.5))\n",
    "test['prob'] = test['pred']\n",
    "test['pred_label'] = test['pred'].map(lambda x: extract_multilabel(x, tp.idx2label, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-16T08:50:06.563862Z",
     "iopub.status.busy": "2022-10-16T08:50:06.562860Z",
     "iopub.status.idle": "2022-10-16T08:50:13.048259Z",
     "shell.execute_reply": "2022-10-16T08:50:13.047114Z",
     "shell.execute_reply.started": "2022-10-16T08:50:06.563818Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "valid.to_csv('./trainsample/valid_event_cls_pred.csv')\n",
    "test.to_csv('./trainsample/test_event_cls_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_csv('./trainsample/valid_event_cls_pred.csv')\n",
    "test = pd.read_csv('./trainsample/test_event_cls_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid['pred_label'] = valid['pred_label'].map(lambda x: ast.literal_eval(x))\n",
    "valid['event_label'] = valid['event_label'].map(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_sample': 1492,\n",
       " 'n_pos': 1651,\n",
       " 'precision': 0.9428911362284355,\n",
       " 'recall': 0.9600242277407631,\n",
       " 'f1': 0.9513805522208884,\n",
       " 'accuracy': 0.9072696050372067}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_evaluation(valid['event_label'].values, valid['pred_label'].values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}