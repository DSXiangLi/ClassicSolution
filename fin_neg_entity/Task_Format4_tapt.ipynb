{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from transformers import BertConfig, BertForMaskedLM, DataCollatorForWholeWordMask,\\\n",
    "    BertTokenizer, TrainingArguments, Trainer\n",
    "from src.train_utils import set_seed,TrainParams, get_torch_device\n",
    "from dataset import data_loader, SeqMlmDataset\n",
    "import torch \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-15T02:18:12.595479Z",
     "iopub.status.busy": "2022-09-15T02:18:12.592593Z",
     "iopub.status.idle": "2022-09-15T02:18:12.679200Z",
     "shell.execute_reply": "2022-09-15T02:18:12.677997Z",
     "shell.execute_reply.started": "2022-09-15T02:18:12.595440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "tp = TrainParams(\n",
    "    log_steps = 10,\n",
    "    save_steps = 50,\n",
    "    epoch_size= 10,\n",
    "    max_seq_len=512,\n",
    "    batch_size=12,\n",
    "    pretrain_model = 'hfl/chinese-roberta-wwm-ext',\n",
    "    max_to_save=3\n",
    ") \n",
    "device = get_torch_device()\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Adaptive Continue Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-15T02:20:25.045286Z",
     "iopub.status.busy": "2022-09-15T02:20:25.044700Z",
     "iopub.status.idle": "2022-09-15T02:20:27.785219Z",
     "shell.execute_reply": "2022-09-15T02:20:27.784229Z",
     "shell.execute_reply.started": "2022-09-15T02:20:25.045243Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(tp.pretrain_model, do_lower_case=True)\n",
    "train_dataset = SeqMlmDataset(data_loader('./trainsample/train_mlm.txt'), tp.max_seq_len, tokenizer)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./checkpoint/tapt',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=tp.epoch_size,\n",
    "    per_device_train_batch_size=tp.batch_size,\n",
    "    save_steps=tp.save_steps,\n",
    "    save_total_limit=tp.max_to_save\n",
    ")\n",
    "\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained(tp.pretrain_model).to(device)\n",
    "data_collator = DataCollatorForWholeWordMask(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-09-15T02:22:27.112622Z",
     "iopub.status.busy": "2022-09-15T02:22:27.111863Z",
     "iopub.status.idle": "2022-09-15T03:57:24.285924Z",
     "shell.execute_reply": "2022-09-15T03:57:24.284971Z",
     "shell.execute_reply.started": "2022-09-15T02:22:27.112578Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9962\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 12\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 12\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8310\n",
      "The following columns in the training set don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: chinese_ref. If chinese_ref are not expected by `BertForMaskedLM.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8310' max='8310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8310/8310 1:34:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.505200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.463500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.433600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.425200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.392800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.392600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.359400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.365400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.347300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.346600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.330400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.318600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.326300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.305100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.312100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.302700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-50\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-50/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-50/pytorch_model.bin\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-100\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-100/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-100/pytorch_model.bin\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-150\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-150/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-150/pytorch_model.bin\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-200\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-200/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-50] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-250\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-250/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-250/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-300\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-300/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-300/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-150] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-350\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-350/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-350/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-400\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-400/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-250] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-450\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-450/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-450/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-300] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-500\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-500/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-500/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-350] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-550\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-550/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-550/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-600\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-600/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-450] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-650\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-650/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-650/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-700\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-700/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-700/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-550] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-750\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-750/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-750/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-800\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-800/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-650] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-850\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-850/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-850/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-700] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-900\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-900/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-900/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-750] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-950\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-950/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-950/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1000\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1000/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-850] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1050\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1050/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1050/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-900] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1100\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1100/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1100/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-950] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1150\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1150/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1150/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1200\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1200/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1050] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1250\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1250/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1250/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1300\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1300/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1300/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1150] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1350\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1350/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1350/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1400\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1400/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1250] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1450\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1450/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1450/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1300] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1500\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1500/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1350] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1550\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1550/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1550/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1600\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1600/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1450] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1650\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1650/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1650/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1700\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1700/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1700/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1550] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1750\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1750/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1750/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1800\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1800/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1650] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1850\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1850/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1850/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1700] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1900\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1900/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1900/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1750] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-1950\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-1950/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-1950/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2000\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2000/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1850] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2050\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2050/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2050/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1900] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2100\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2100/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2100/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-1950] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2150\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2150/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2150/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2200\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2200/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2050] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2250\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2250/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2250/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2300\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2300/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2300/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2150] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2350\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2350/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2350/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2400\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2400/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2250] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2450\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2450/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2450/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2300] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2500\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2500/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2500/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2350] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2550\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2550/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2550/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2600\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2600/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2450] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2650\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2650/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2650/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2700\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2700/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2700/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2550] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2750\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2750/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2750/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2800\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2800/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2650] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2850\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2850/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2850/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2700] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2900\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2900/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2900/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2750] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-2950\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-2950/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-2950/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3000\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3000/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2850] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3050\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3050/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3050/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2900] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3100\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3100/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3100/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-2950] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3150\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3150/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3150/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3200\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3200/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3050] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3250\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3250/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3250/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3300\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3300/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3300/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3150] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3350\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3350/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3350/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3400\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3400/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3250] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3450\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3450/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3450/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3300] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3500\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3500/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3500/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3350] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3550\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3550/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3550/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3600\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3600/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3450] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3650\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3650/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3650/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3700\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3700/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3700/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3550] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3750\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3750/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3750/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3800\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3800/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3650] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3850\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3850/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3850/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3700] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3900\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3900/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3900/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3750] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-3950\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-3950/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-3950/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4000\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4000/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3850] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4050\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4050/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4050/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3900] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4100\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4100/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4100/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-3950] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4150\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4150/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4150/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4200\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4200/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4050] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4250\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4250/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4250/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4300\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4300/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4300/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4150] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4350\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4350/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4350/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4400\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4400/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4250] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4450\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4450/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4450/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4300] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4500\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4500/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4500/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4350] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4550\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4550/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4550/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4600\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4600/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4450] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4650\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4650/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4650/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4700\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4700/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4700/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4550] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4750\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4750/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4750/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4800\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4800/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4650] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4850\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4850/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4850/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4700] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4900\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4900/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4900/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4750] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-4950\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-4950/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-4950/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5000\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5000/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4850] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5050\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5050/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5050/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4900] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5100\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5100/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5100/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-4950] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5150\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5150/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5150/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5200\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5200/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5050] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5250\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5250/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5250/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5300\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5300/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5300/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5150] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5350\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5350/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5350/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5400\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5400/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5250] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5450\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5450/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5450/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5300] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5500\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5500/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5500/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5350] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5550\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5550/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5550/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5600\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5600/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5450] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5650\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5650/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5650/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5700\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5700/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5700/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5550] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5750\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5750/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5750/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5800\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5800/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5650] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5850\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5850/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5850/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5700] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5900\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5900/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5900/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5750] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-5950\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-5950/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-5950/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6000\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6000/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5850] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6050\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6050/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6050/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5900] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6100\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6100/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6100/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-5950] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6150\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6150/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6150/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6200\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6200/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6050] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6250\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6250/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6250/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6300\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6300/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6300/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6150] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6350\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6350/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6350/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6400\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6400/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6250] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6450\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6450/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6450/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6300] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6500\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6500/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6500/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6350] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6550\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6550/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6550/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6600\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6600/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6450] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6650\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6650/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6650/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6700\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6700/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6700/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6550] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6750\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6750/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6750/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6800\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6800/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6650] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6850\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6850/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6850/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6700] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6900\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6900/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6900/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6750] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-6950\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-6950/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-6950/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7000\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7000/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6850] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7050\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7050/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7050/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6900] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7100\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7100/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7100/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-6950] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7150\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7150/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7150/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7200\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7200/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7050] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7250\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7250/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7250/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7300\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7300/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7300/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7150] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7350\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7350/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7350/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7200] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7400\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7400/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7400/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7250] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7450\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7450/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7450/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7300] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7500\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7500/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7500/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7350] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7550\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7550/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7550/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7400] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7600\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7600/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7600/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7450] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7650\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7650/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7650/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7700\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7700/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7700/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7550] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7750\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7750/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7750/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7600] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7800\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7800/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7800/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7650] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7850\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7850/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7850/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7700] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7900\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7900/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7900/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7750] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-7950\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-7950/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-7950/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7800] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-8000\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-8000/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7850] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-8050\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-8050/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-8050/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7900] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-8100\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-8100/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-8100/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-7950] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-8150\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-8150/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-8150/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-8200\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-8200/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-8200/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-8050] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-8250\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-8250/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-8250/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-8100] due to args.save_total_limit\n",
      "Saving model checkpoint to ./checkpoint/tapt/checkpoint-8300\n",
      "Configuration saved in ./checkpoint/tapt/checkpoint-8300/config.json\n",
      "Model weights saved in ./checkpoint/tapt/checkpoint-8300/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoint/tapt/checkpoint-8150] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train()\n",
    "output_train_file = os.path.join(training_args.output_dir, \"train_results.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-15T04:10:03.822837Z",
     "iopub.status.busy": "2022-09-15T04:10:03.822440Z",
     "iopub.status.idle": "2022-09-15T04:10:04.561797Z",
     "shell.execute_reply": "2022-09-15T04:10:04.560743Z",
     "shell.execute_reply.started": "2022-09-15T04:10:03.822801Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to tapt_10epoch\n",
      "Configuration saved in tapt_10epoch/config.json\n",
      "Model weights saved in tapt_10epoch/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('tapt_10epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multitask finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-15T04:11:22.038350Z",
     "iopub.status.busy": "2022-09-15T04:11:22.037491Z",
     "iopub.status.idle": "2022-09-15T04:11:22.494017Z",
     "shell.execute_reply": "2022-09-15T04:11:22.493065Z",
     "shell.execute_reply.started": "2022-09-15T04:11:22.038312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import collections \n",
    "from itertools import chain\n",
    "import torch \n",
    "import time \n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from src.train_utils import set_seed, ModelSave, get_torch_device, EarlyStop, TrainParams\n",
    "from src.evaluation import binary_cls_report, classification_inference\n",
    "from src.metric import  binary_cls_metrics, binary_cls_log\n",
    "\n",
    "from models import BertClassifier,BertMtl\n",
    "from dataset import SeqPairMtlDataset, data_loader\n",
    "from evaluation import overall_f1\n",
    "import transformers \n",
    "transformers.logging.set_verbosity_error()\n",
    "from transformers import BertTokenizer,AdamW, get_linear_schedule_with_warmup\n",
    "device = get_torch_device()\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-15T04:11:24.708897Z",
     "iopub.status.busy": "2022-09-15T04:11:24.708277Z",
     "iopub.status.idle": "2022-09-15T04:11:24.715817Z",
     "shell.execute_reply": "2022-09-15T04:11:24.714812Z",
     "shell.execute_reply.started": "2022-09-15T04:11:24.708859Z"
    }
   },
   "outputs": [],
   "source": [
    "tp = TrainParams(\n",
    "    log_steps = 10,\n",
    "    save_steps = 10000,\n",
    "    epoch_size=20,\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    max_seq_len=512,\n",
    "    batch_size=20,\n",
    "    lr=5e-6,\n",
    "    weight_decay=0.0,\n",
    "    epsilon=1e-6,\n",
    "    warmup_steps=100,\n",
    "    dropout_rate=0.5,\n",
    "    label_size=2,\n",
    "    gradient_clip=1.0,\n",
    "    hidden_s=200,\n",
    "    hidden_e=200,\n",
    "    early_stop_params = {\n",
    "        'monitor':'f1',\n",
    "        'mode':'max',\n",
    "        'min_delta': 0,\n",
    "        'patience':3,\n",
    "        'verbose':False\n",
    "    },\n",
    "    tokenizer = 'hfl/chinese-roberta-wwm-ext', \n",
    "    pretrain_model = './checkpoint/tapt_10epoch',\n",
    "    continue_train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-15T04:11:26.767492Z",
     "iopub.status.busy": "2022-09-15T04:11:26.767119Z",
     "iopub.status.idle": "2022-09-15T04:12:03.868905Z",
     "shell.execute_reply": "2022-09-15T04:12:03.867797Z",
     "shell.execute_reply.started": "2022-09-15T04:11:26.767459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 4 tokens\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('hfl/chinese-roberta-wwm-ext', do_lower_case=True)\n",
    "special_tokens_dict = {'additional_special_tokens':['[t]','[c]','[o]','[e]']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print('We have added', num_added_toks, 'tokens')\n",
    "\n",
    "train_dataset = SeqPairMtlDataset(data_loader('./trainsample/train4.txt'), tp.max_seq_len, tokenizer)\n",
    "valid_dataset = SeqPairMtlDataset(data_loader('./trainsample/valid4.txt'), tp.max_seq_len, tokenizer)\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "valid_sampler = SequentialSampler(valid_dataset)\n",
    "train_loader = DataLoader(train_dataset, sampler=train_sampler, batch_size=tp.batch_size)\n",
    "valid_loader = DataLoader(valid_dataset, sampler=valid_sampler, batch_size=tp.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-15T04:22:05.283644Z",
     "iopub.status.busy": "2022-09-15T04:22:05.282886Z",
     "iopub.status.idle": "2022-09-15T04:22:07.137836Z",
     "shell.execute_reply": "2022-09-15T04:22:07.136721Z",
     "shell.execute_reply.started": "2022-09-15T04:22:05.283595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoint/single_task_bert5 model cleaned\n"
     ]
    }
   ],
   "source": [
    "tp.update({'num_train_steps': int(len(train_loader)*tp.epoch_size)})\n",
    "\n",
    "CKPT = './checkpoint/single_task_bert5'\n",
    "saver = ModelSave(CKPT, continue_train=False)\n",
    "saver.init()\n",
    "es = EarlyStop(**tp.early_stop_params)\n",
    "global_step = 0\n",
    "tb = SummaryWriter(CKPT)\n",
    "\n",
    "model = BertMtl(tp)\n",
    "model.bert.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "model.to(device)\n",
    "optimizer, scheduler = model.get_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-15T04:58:22.959221Z",
     "iopub.status.busy": "2022-09-15T04:58:22.958641Z",
     "iopub.status.idle": "2022-09-15T05:57:56.827715Z",
     "shell.execute_reply": "2022-09-15T05:57:56.826251Z",
     "shell.execute_reply.started": "2022-09-15T04:58:22.959157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   2    |   10    |   0.398738   |     -     |   11.32  \n",
      "   2    |   20    |   0.380345   |     -     |   10.23  \n",
      "   2    |   30    |   0.298078   |     -     |   10.23  \n",
      "   2    |   40    |   0.366752   |     -     |   10.22  \n",
      "   2    |   50    |   0.356135   |     -     |   10.24  \n",
      "   2    |   60    |   0.323243   |     -     |   10.24  \n",
      "   2    |   70    |   0.345801   |     -     |   10.22  \n",
      "   2    |   80    |   0.360564   |     -     |   10.22  \n",
      "   2    |   90    |   0.326366   |     -     |   10.28  \n",
      "   2    |   100   |   0.280422   |     -     |   10.22  \n",
      "   2    |   110   |   0.407383   |     -     |   10.22  \n",
      "   2    |   120   |   0.323768   |     -     |   10.26  \n",
      "   2    |   130   |   0.315418   |     -     |   10.26  \n",
      "   2    |   140   |   0.342691   |     -     |   10.23  \n",
      "   2    |   150   |   0.392780   |     -     |   10.23  \n",
      "   2    |   160   |   0.353140   |     -     |   10.22  \n",
      "   2    |   170   |   0.336684   |     -     |   10.21  \n",
      "   2    |   180   |   0.285774   |     -     |   10.32  \n",
      "   2    |   190   |   0.258501   |     -     |   10.24  \n",
      "   2    |   200   |   0.332170   |     -     |   10.19  \n",
      "   2    |   210   |   0.323938   |     -     |   10.22  \n",
      "   2    |   220   |   0.291749   |     -     |   10.25  \n",
      "   2    |   230   |   0.265742   |     -     |   10.22  \n",
      "   2    |   240   |   0.290119   |     -     |   10.22  \n",
      "   2    |   250   |   0.304507   |     -     |   10.28  \n",
      "   2    |   260   |   0.218204   |     -     |   10.27  \n",
      "   2    |   270   |   0.245355   |     -     |   10.24  \n",
      "   2    |   280   |   0.195466   |     -     |   10.23  \n",
      "   2    |   290   |   0.297795   |     -     |   10.21  \n",
      "   2    |   300   |   0.345524   |     -     |   10.22  \n",
      "   2    |   310   |   0.290332   |     -     |   10.22  \n",
      "   2    |   320   |   0.256418   |     -     |   10.24  \n",
      "   2    |   330   |   0.237284   |     -     |   10.21  \n",
      "   2    |   340   |   0.276615   |     -     |   10.26  \n",
      "   2    |   350   |   0.257128   |     -     |   10.24  \n",
      "   2    |   360   |   0.418673   |     -     |   10.24  \n",
      "   2    |   370   |   0.398008   |     -     |   10.24  \n",
      "   2    |   372   |   0.237709   |     -     |   2.04   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.316802   |  2.545256  |  418.51  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  |  Val AUC  |  Val AP   | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   2    |  92.225%  |  97.675%  |  97.648%  |  92.225%  |  92.225%  |  92.225%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   3    |   10    |   0.243276   |     -     |   11.26  \n",
      "   3    |   20    |   0.211220   |     -     |   10.29  \n",
      "   3    |   30    |   0.262235   |     -     |   10.23  \n",
      "   3    |   40    |   0.296800   |     -     |   10.23  \n",
      "   3    |   50    |   0.310745   |     -     |   10.25  \n",
      "   3    |   60    |   0.229652   |     -     |   10.27  \n",
      "   3    |   70    |   0.191415   |     -     |   10.21  \n",
      "   3    |   80    |   0.201975   |     -     |   10.25  \n",
      "   3    |   90    |   0.199262   |     -     |   10.21  \n",
      "   3    |   100   |   0.129538   |     -     |   10.26  \n",
      "   3    |   110   |   0.288615   |     -     |   10.24  \n",
      "   3    |   120   |   0.171242   |     -     |   10.22  \n",
      "   3    |   130   |   0.210253   |     -     |   10.24  \n",
      "   3    |   140   |   0.175774   |     -     |   10.23  \n",
      "   3    |   150   |   0.445951   |     -     |   10.29  \n",
      "   3    |   160   |   0.304655   |     -     |   10.23  \n",
      "   3    |   170   |   0.130090   |     -     |   10.20  \n",
      "   3    |   180   |   0.244970   |     -     |   10.25  \n",
      "   3    |   190   |   0.224965   |     -     |   10.24  \n",
      "   3    |   200   |   0.238640   |     -     |   10.23  \n",
      "   3    |   210   |   0.156335   |     -     |   10.23  \n",
      "   3    |   220   |   0.198893   |     -     |   10.25  \n",
      "   3    |   230   |   0.213120   |     -     |   10.25  \n",
      "   3    |   240   |   0.126676   |     -     |   10.26  \n",
      "   3    |   250   |   0.167470   |     -     |   10.22  \n",
      "   3    |   260   |   0.180356   |     -     |   10.22  \n",
      "   3    |   270   |   0.157915   |     -     |   10.23  \n",
      "   3    |   280   |   0.198995   |     -     |   10.23  \n",
      "   3    |   290   |   0.199798   |     -     |   10.21  \n",
      "   3    |   300   |   0.221032   |     -     |   10.25  \n",
      "   3    |   310   |   0.168156   |     -     |   10.22  \n",
      "   3    |   320   |   0.268241   |     -     |   10.24  \n",
      "   3    |   330   |   0.169564   |     -     |   10.26  \n",
      "   3    |   340   |   0.261420   |     -     |   10.22  \n",
      "   3    |   350   |   0.138898   |     -     |   10.22  \n",
      "   3    |   360   |   0.133581   |     -     |   10.29  \n",
      "   3    |   370   |   0.220910   |     -     |   10.24  \n",
      "   3    |   372   |   0.068572   |     -     |   2.03   \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   0.213190   |  2.900733  |  415.06  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  |  Val AUC  |  Val AP   | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   3    |  93.834%  |  98.126%  |  98.136%  |  93.834%  |  93.834%  |  93.834%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   4    |   10    |   0.119421   |     -     |   11.27  \n",
      "   4    |   20    |   0.193642   |     -     |   10.22  \n",
      "   4    |   30    |   0.167396   |     -     |   10.22  \n",
      "   4    |   40    |   0.218643   |     -     |   10.22  \n",
      "   4    |   50    |   0.242970   |     -     |   10.30  \n",
      "   4    |   60    |   0.076856   |     -     |   10.22  \n",
      "   4    |   70    |   0.171715   |     -     |   10.24  \n",
      "   4    |   80    |   0.128605   |     -     |   10.23  \n",
      "   4    |   90    |   0.266142   |     -     |   10.24  \n",
      "   4    |   100   |   0.194940   |     -     |   10.25  \n",
      "   4    |   110   |   0.247303   |     -     |   10.22  \n",
      "   4    |   120   |   0.203706   |     -     |   10.21  \n",
      "   4    |   130   |   0.080675   |     -     |   10.22  \n",
      "   4    |   140   |   0.178386   |     -     |   10.27  \n",
      "   4    |   150   |   0.166907   |     -     |   10.22  \n",
      "   4    |   160   |   0.143259   |     -     |   10.22  \n",
      "   4    |   170   |   0.060472   |     -     |   10.31  \n",
      "   4    |   180   |   0.232838   |     -     |   10.24  \n",
      "   4    |   190   |   0.147106   |     -     |   10.22  \n",
      "   4    |   200   |   0.109304   |     -     |   10.27  \n",
      "   4    |   210   |   0.149140   |     -     |   10.21  \n",
      "   4    |   220   |   0.133564   |     -     |   10.25  \n",
      "   4    |   230   |   0.150793   |     -     |   10.23  \n",
      "   4    |   240   |   0.122554   |     -     |   10.21  \n",
      "   4    |   250   |   0.113878   |     -     |   10.23  \n",
      "   4    |   260   |   0.156037   |     -     |   10.25  \n",
      "   4    |   270   |   0.169918   |     -     |   10.23  \n",
      "   4    |   280   |   0.201130   |     -     |   10.23  \n",
      "   4    |   290   |   0.214045   |     -     |   10.23  \n",
      "   4    |   300   |   0.114838   |     -     |   10.21  \n",
      "   4    |   310   |   0.161870   |     -     |   10.25  \n",
      "   4    |   320   |   0.153498   |     -     |   10.29  \n",
      "   4    |   330   |   0.190008   |     -     |   10.25  \n",
      "   4    |   340   |   0.174501   |     -     |   10.25  \n",
      "   4    |   350   |   0.102434   |     -     |   10.24  \n",
      "   4    |   360   |   0.220031   |     -     |   10.27  \n",
      "   4    |   370   |   0.209937   |     -     |   10.21  \n",
      "   4    |   372   |   0.100972   |     -     |   2.04   \n",
      "----------------------------------------------------------------------\n",
      "   4    |    -    |   0.164532   |  3.227093  |  415.18  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  |  Val AUC  |  Val AP   | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   4    |  94.692%  |  98.410%  |  98.446%  |  94.692%  |  94.692%  |  94.692%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   5    |   10    |   0.191350   |     -     |   11.26  \n",
      "   5    |   20    |   0.086018   |     -     |   10.21  \n",
      "   5    |   30    |   0.240503   |     -     |   10.21  \n",
      "   5    |   40    |   0.104483   |     -     |   10.26  \n",
      "   5    |   50    |   0.112003   |     -     |   10.23  \n",
      "   5    |   60    |   0.080396   |     -     |   10.22  \n",
      "   5    |   70    |   0.075052   |     -     |   10.24  \n",
      "   5    |   80    |   0.137578   |     -     |   10.27  \n",
      "   5    |   90    |   0.114729   |     -     |   10.22  \n",
      "   5    |   100   |   0.080469   |     -     |   10.24  \n",
      "   5    |   110   |   0.161442   |     -     |   10.21  \n",
      "   5    |   120   |   0.082381   |     -     |   10.25  \n",
      "   5    |   130   |   0.032675   |     -     |   10.24  \n",
      "   5    |   140   |   0.036881   |     -     |   10.23  \n",
      "   5    |   150   |   0.185952   |     -     |   10.21  \n",
      "   5    |   160   |   0.175409   |     -     |   10.24  \n",
      "   5    |   170   |   0.195067   |     -     |   10.23  \n",
      "   5    |   180   |   0.133152   |     -     |   10.23  \n",
      "   5    |   190   |   0.093279   |     -     |   10.21  \n",
      "   5    |   200   |   0.207547   |     -     |   10.31  \n",
      "   5    |   210   |   0.068555   |     -     |   10.27  \n",
      "   5    |   220   |   0.165636   |     -     |   10.22  \n",
      "   5    |   230   |   0.093149   |     -     |   10.24  \n",
      "   5    |   240   |   0.191693   |     -     |   10.20  \n",
      "   5    |   250   |   0.185826   |     -     |   10.24  \n",
      "   5    |   260   |   0.146160   |     -     |   10.25  \n",
      "   5    |   270   |   0.083159   |     -     |   10.23  \n",
      "   5    |   280   |   0.067852   |     -     |   10.23  \n",
      "   5    |   290   |   0.221602   |     -     |   10.24  \n",
      "   5    |   300   |   0.103878   |     -     |   10.24  \n",
      "   5    |   310   |   0.126769   |     -     |   10.22  \n",
      "   5    |   320   |   0.058155   |     -     |   10.23  \n",
      "   5    |   330   |   0.164032   |     -     |   10.22  \n",
      "   5    |   340   |   0.144412   |     -     |   10.26  \n",
      "   5    |   350   |   0.198411   |     -     |   10.24  \n",
      "   5    |   360   |   0.186776   |     -     |   10.20  \n",
      "   5    |   370   |   0.122376   |     -     |   10.22  \n",
      "   5    |   372   |   0.010443   |     -     |   2.04   \n",
      "----------------------------------------------------------------------\n",
      "   5    |    -    |   0.131076   |  3.463188  |  415.07  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  |  Val AUC  |  Val AP   | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   5    |  94.692%  |  98.463%  |  98.494%  |  94.692%  |  94.692%  |  94.692%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   6    |   10    |   0.105219   |     -     |   11.26  \n",
      "   6    |   20    |   0.111868   |     -     |   10.22  \n",
      "   6    |   30    |   0.063818   |     -     |   10.25  \n",
      "   6    |   40    |   0.135581   |     -     |   10.25  \n",
      "   6    |   50    |   0.063870   |     -     |   10.22  \n",
      "   6    |   60    |   0.086158   |     -     |   10.23  \n",
      "   6    |   70    |   0.041506   |     -     |   10.25  \n",
      "   6    |   80    |   0.109552   |     -     |   10.21  \n",
      "   6    |   90    |   0.159045   |     -     |   10.21  \n",
      "   6    |   100   |   0.102240   |     -     |   10.22  \n",
      "   6    |   110   |   0.047614   |     -     |   10.22  \n",
      "   6    |   120   |   0.051203   |     -     |   10.24  \n",
      "   6    |   130   |   0.074818   |     -     |   10.24  \n",
      "   6    |   140   |   0.060701   |     -     |   10.21  \n",
      "   6    |   150   |   0.071317   |     -     |   10.22  \n",
      "   6    |   160   |   0.092057   |     -     |   10.29  \n",
      "   6    |   170   |   0.146947   |     -     |   10.23  \n",
      "   6    |   180   |   0.191342   |     -     |   10.22  \n",
      "   6    |   190   |   0.063995   |     -     |   10.26  \n",
      "   6    |   200   |   0.096561   |     -     |   10.22  \n",
      "   6    |   210   |   0.142322   |     -     |   10.23  \n",
      "   6    |   220   |   0.047448   |     -     |   10.26  \n",
      "   6    |   230   |   0.090991   |     -     |   10.25  \n",
      "   6    |   240   |   0.080662   |     -     |   10.23  \n",
      "   6    |   250   |   0.177415   |     -     |   10.22  \n",
      "   6    |   260   |   0.080888   |     -     |   10.23  \n",
      "   6    |   270   |   0.154942   |     -     |   10.21  \n",
      "   6    |   280   |   0.227127   |     -     |   10.24  \n",
      "   6    |   290   |   0.088479   |     -     |   10.24  \n",
      "   6    |   300   |   0.082231   |     -     |   10.22  \n",
      "   6    |   310   |   0.127524   |     -     |   10.21  \n",
      "   6    |   320   |   0.084517   |     -     |   10.28  \n",
      "   6    |   330   |   0.130876   |     -     |   10.23  \n",
      "   6    |   340   |   0.061146   |     -     |   10.25  \n",
      "   6    |   350   |   0.162535   |     -     |   10.25  \n",
      "   6    |   360   |   0.089038   |     -     |   10.24  \n",
      "   6    |   370   |   0.112652   |     -     |   10.24  \n",
      "   6    |   372   |   0.043452   |     -     |   2.04   \n",
      "----------------------------------------------------------------------\n",
      "   6    |    -    |   0.103103   |  3.761683  |  415.63  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  |  Val AUC  |  Val AP   | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   6    |  95.067%  |  98.436%  |  98.435%  |  95.067%  |  95.067%  |  95.067%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   7    |   10    |   0.033709   |     -     |   11.24  \n",
      "   7    |   20    |   0.136825   |     -     |   10.21  \n",
      "   7    |   30    |   0.091456   |     -     |   10.24  \n",
      "   7    |   40    |   0.062961   |     -     |   10.21  \n",
      "   7    |   50    |   0.055832   |     -     |   10.22  \n",
      "   7    |   60    |   0.120816   |     -     |   10.24  \n",
      "   7    |   70    |   0.078533   |     -     |   10.22  \n",
      "   7    |   80    |   0.081286   |     -     |   10.20  \n",
      "   7    |   90    |   0.072779   |     -     |   10.22  \n",
      "   7    |   100   |   0.138921   |     -     |   10.23  \n",
      "   7    |   110   |   0.197360   |     -     |   10.21  \n",
      "   7    |   120   |   0.057798   |     -     |   10.20  \n",
      "   7    |   130   |   0.085106   |     -     |   10.28  \n",
      "   7    |   140   |   0.019628   |     -     |   10.22  \n",
      "   7    |   150   |   0.015155   |     -     |   10.21  \n",
      "   7    |   160   |   0.088055   |     -     |   10.21  \n",
      "   7    |   170   |   0.135310   |     -     |   10.26  \n",
      "   7    |   180   |   0.074417   |     -     |   10.21  \n",
      "   7    |   190   |   0.017164   |     -     |   10.23  \n",
      "   7    |   200   |   0.109464   |     -     |   10.24  \n",
      "   7    |   210   |   0.098258   |     -     |   10.24  \n",
      "   7    |   220   |   0.133399   |     -     |   10.25  \n",
      "   7    |   230   |   0.152421   |     -     |   10.23  \n",
      "   7    |   240   |   0.098848   |     -     |   10.21  \n",
      "   7    |   250   |   0.059608   |     -     |   10.26  \n",
      "   7    |   260   |   0.083058   |     -     |   10.23  \n",
      "   7    |   270   |   0.047701   |     -     |   10.23  \n",
      "   7    |   280   |   0.117579   |     -     |   10.24  \n",
      "   7    |   290   |   0.066493   |     -     |   10.22  \n",
      "   7    |   300   |   0.098287   |     -     |   10.25  \n",
      "   7    |   310   |   0.127484   |     -     |   10.27  \n",
      "   7    |   320   |   0.072120   |     -     |   10.23  \n",
      "   7    |   330   |   0.047009   |     -     |   10.22  \n",
      "   7    |   340   |   0.111957   |     -     |   10.24  \n",
      "   7    |   350   |   0.051661   |     -     |   10.25  \n",
      "   7    |   360   |   0.055159   |     -     |   10.23  \n",
      "   7    |   370   |   0.197015   |     -     |   10.22  \n",
      "   7    |   372   |   0.007621   |     -     |   2.03   \n",
      "----------------------------------------------------------------------\n",
      "   7    |    -    |   0.088589   |  3.849735  |  414.91  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  |  Val AUC  |  Val AP   | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   7    |  95.013%  |  98.488%  |  98.501%  |  95.013%  |  95.013%  |  95.013%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   8    |   10    |   0.076071   |     -     |   11.26  \n",
      "   8    |   20    |   0.023607   |     -     |   10.21  \n",
      "   8    |   30    |   0.017797   |     -     |   10.27  \n",
      "   8    |   40    |   0.061361   |     -     |   10.24  \n",
      "   8    |   50    |   0.074282   |     -     |   10.22  \n",
      "   8    |   60    |   0.060661   |     -     |   10.28  \n",
      "   8    |   70    |   0.058510   |     -     |   10.22  \n",
      "   8    |   80    |   0.110405   |     -     |   10.23  \n",
      "   8    |   90    |   0.045881   |     -     |   10.23  \n",
      "   8    |   100   |   0.099768   |     -     |   10.21  \n",
      "   8    |   110   |   0.034317   |     -     |   10.21  \n",
      "   8    |   120   |   0.120397   |     -     |   10.23  \n",
      "   8    |   130   |   0.286572   |     -     |   10.22  \n",
      "   8    |   140   |   0.094178   |     -     |   10.22  \n",
      "   8    |   150   |   0.051075   |     -     |   10.21  \n",
      "   8    |   160   |   0.089861   |     -     |   10.22  \n",
      "   8    |   170   |   0.100557   |     -     |   10.24  \n",
      "   8    |   180   |   0.007388   |     -     |   10.23  \n",
      "   8    |   190   |   0.023287   |     -     |   10.20  \n",
      "   8    |   200   |   0.046710   |     -     |   10.22  \n",
      "   8    |   210   |   0.087018   |     -     |   10.28  \n",
      "   8    |   220   |   0.058557   |     -     |   10.23  \n",
      "   8    |   230   |   0.045781   |     -     |   10.20  \n",
      "   8    |   240   |   0.068103   |     -     |   10.22  \n",
      "   8    |   250   |   0.068006   |     -     |   10.27  \n",
      "   8    |   260   |   0.071001   |     -     |   10.22  \n",
      "   8    |   270   |   0.005474   |     -     |   10.21  \n",
      "   8    |   280   |   0.051469   |     -     |   10.28  \n",
      "   8    |   290   |   0.102225   |     -     |   10.23  \n",
      "   8    |   300   |   0.053339   |     -     |   10.26  \n",
      "   8    |   310   |   0.075602   |     -     |   10.23  \n",
      "   8    |   320   |   0.087371   |     -     |   10.22  \n",
      "   8    |   330   |   0.123169   |     -     |   10.19  \n",
      "   8    |   340   |   0.084069   |     -     |   10.27  \n",
      "   8    |   350   |   0.062153   |     -     |   10.22  \n",
      "   8    |   360   |   0.076765   |     -     |   10.20  \n",
      "   8    |   370   |   0.151416   |     -     |   10.26  \n",
      "   8    |   372   |   0.006106   |     -     |   2.05   \n",
      "----------------------------------------------------------------------\n",
      "   8    |    -    |   0.074275   |  4.058090  |  414.88  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  |  Val AUC  |  Val AP   | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   8    |  95.013%  |  98.483%  |  98.474%  |  95.013%  |  95.013%  |  95.013%  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss   |  Elapsed \n",
      "------------------------------------------------------------\n",
      "   9    |   10    |   0.051358   |     -     |   11.23  \n",
      "   9    |   20    |   0.038568   |     -     |   10.26  \n",
      "   9    |   30    |   0.040426   |     -     |   10.25  \n",
      "   9    |   40    |   0.100085   |     -     |   10.21  \n",
      "   9    |   50    |   0.015958   |     -     |   10.22  \n",
      "   9    |   60    |   0.057446   |     -     |   10.23  \n",
      "   9    |   70    |   0.111544   |     -     |   10.21  \n",
      "   9    |   80    |   0.125133   |     -     |   10.23  \n",
      "   9    |   90    |   0.011156   |     -     |   10.30  \n",
      "   9    |   100   |   0.009467   |     -     |   10.24  \n",
      "   9    |   110   |   0.036450   |     -     |   10.20  \n",
      "   9    |   120   |   0.012482   |     -     |   10.28  \n",
      "   9    |   130   |   0.045829   |     -     |   10.22  \n",
      "   9    |   140   |   0.024025   |     -     |   10.24  \n",
      "   9    |   150   |   0.036870   |     -     |   10.26  \n",
      "   9    |   160   |   0.031026   |     -     |   10.24  \n",
      "   9    |   170   |   0.069126   |     -     |   10.21  \n",
      "   9    |   180   |   0.041841   |     -     |   10.23  \n",
      "   9    |   190   |   0.065989   |     -     |   10.22  \n",
      "   9    |   200   |   0.130283   |     -     |   10.27  \n",
      "   9    |   210   |   0.154617   |     -     |   10.27  \n",
      "   9    |   220   |   0.043865   |     -     |   10.24  \n",
      "   9    |   230   |   0.042029   |     -     |   10.20  \n",
      "   9    |   240   |   0.048178   |     -     |   10.22  \n",
      "   9    |   250   |   0.055174   |     -     |   10.25  \n",
      "   9    |   260   |   0.021552   |     -     |   10.22  \n",
      "   9    |   270   |   0.111046   |     -     |   10.24  \n",
      "   9    |   280   |   0.044593   |     -     |   10.21  \n",
      "   9    |   290   |   0.118288   |     -     |   10.26  \n",
      "   9    |   300   |   0.037749   |     -     |   10.33  \n",
      "   9    |   310   |   0.035565   |     -     |   10.22  \n",
      "   9    |   320   |   0.078017   |     -     |   10.20  \n",
      "   9    |   330   |   0.066926   |     -     |   10.26  \n",
      "   9    |   340   |   0.082651   |     -     |   10.22  \n",
      "   9    |   350   |   0.065178   |     -     |   10.24  \n",
      "   9    |   360   |   0.026322   |     -     |   10.23  \n",
      "   9    |   370   |   0.008196   |     -     |   10.22  \n",
      "   9    |   372   |   0.483330   |     -     |   2.05   \n",
      "----------------------------------------------------------------------\n",
      "   9    |    -    |   0.059054   |  4.175942  |  415.46  \n",
      "\n",
      "\n",
      " Epoch  |  Val Acc  |  Val AUC  |  Val AP   | Precision |  Recall   |  Val F1  \n",
      "--------------------------------------------------------------------------------\n",
      "   9    |  94.906%  |  98.373%  |  98.308%  |  94.906%  |  94.906%  |  94.906%  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(1, tp['epoch_size']):\n",
    "    print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10}  | {'Elapsed':^9}\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    # Measure the elapsed time of each epoch\n",
    "    t0_epoch, t0_batch = time.time(), time.time()\n",
    "    total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        global_step +=1\n",
    "        batch_counts +=1\n",
    "\n",
    "        #Forward propogate\n",
    "        model.zero_grad()\n",
    "        feature = {k:v.to(device) for k, v in batch.items()}\n",
    "        logits = model(feature)\n",
    "        loss = model.compute_loss(feature, logits)\n",
    "        batch_loss += loss.item()\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), tp.gradient_clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # Log steps for train loss logging\n",
    "        if (step % tp.log_steps == 0 and step != 0) or (step == len(train_loader) - 1):\n",
    "            time_elapsed = time.time() - t0_batch\n",
    "            print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "            tb.add_scalar('loss/batch_train', batch_loss / batch_counts, global_step=global_step)\n",
    "            batch_loss, batch_counts = 0, 0\n",
    "            t0_batch = time.time()\n",
    "\n",
    "        # Save steps for ckpt saving and dev evaluation\n",
    "        if (step % tp.save_steps == 0 and step != 0) or (step == len(train_loader) - 1):\n",
    "            val_metrics = binary_cls_metrics(model, valid_loader, device, label_name='label1')\n",
    "            for key, val in val_metrics.items():\n",
    "                tb.add_scalar(f'metric/{key}', val, global_step=global_step)\n",
    "            avg_train_loss = total_loss / step\n",
    "            tb.add_scalars('loss/train_valid',{'train': avg_train_loss,\n",
    "                                                'valid': val_metrics['val_loss']}, global_step=global_step)\n",
    "            saver(total_loss / step, val_metrics['val_loss'], epoch_i, global_step, model, optimizer, scheduler)\n",
    "\n",
    "    # On Epoch End: calcualte train & valid loss and log overall metrics\n",
    "    time_elapsed = time.time() - t0_epoch\n",
    "    val_metrics = binary_cls_metrics(model, valid_loader, device, label_name='label1')\n",
    "    avg_train_loss = total_loss / step\n",
    "\n",
    "    print(\"-\"*70)\n",
    "    print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_metrics['val_loss']:^10.6f} | {time_elapsed:^9.2f}\")\n",
    "    binary_cls_log(epoch_i, val_metrics)\n",
    "    print(\"\\n\")\n",
    "    if es.check(val_metrics):\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-15T05:58:43.661028Z",
     "iopub.status.busy": "2022-09-15T05:58:43.660611Z",
     "iopub.status.idle": "2022-09-15T05:59:14.525959Z",
     "shell.execute_reply": "2022-09-15T05:59:14.525004Z",
     "shell.execute_reply.started": "2022-09-15T05:58:43.660993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_s': 0.9561561561561561,\n",
       " 'f1_e': 0.9499736703528172,\n",
       " 'f1': 0.9524466646741527}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = classification_inference(model, valid_loader, device)\n",
    "valid = pd.read_csv('./trainsample/valid.csv')\n",
    "valid['pred'] = result['pred']\n",
    "valid['prob'] = result['prob']\n",
    "valid.loc[:,['id','single_entity','pred','prob']].to_csv('valid5.csv')\n",
    "overall_f1(valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
